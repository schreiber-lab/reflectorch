{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary methods from the `reflectorch` package, as well as other basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from reflectorch import SAVED_MODELS_DIR, SaveBestModel, StepLR, get_trainer_by_name, get_callbacks_by_name\n",
    "from reflectorch.extensions.jupyter import JPlotLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "Alternatively, we can import everything from reflectorch with\n",
    "`from reflectorch import *`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model we use the `Trainer` class, which contains all the components necessary for the training process such as the data generator, the neural network and the optimizer.\n",
    "\n",
    " We can initialize the trainer according to the specifications defined in a YAML configuration file using the `get_trainer_by_name` method which takes as input the name of the configuration file. If the package was installed in editable model, the configuration files are read from the `configs` directory located inside the repository, otherwise the path to the directory containing the configuration file should also be specified using the `config_dir` argument. The `load_weights` argument should be set to `False` since we want the neural network weights to be randomly initialized for a fresh training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a_base_point_xray_conv_standard loaded. Number of parameters: 5.02 M\n"
     ]
    }
   ],
   "source": [
    "config_name = 'a_base_point_xray_conv_standard'\n",
    "trainer = get_trainer_by_name(config_name, load_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The trainer contains several important attributes we can inspect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. The Pytorch optimizer. We can observe that the optimizer specified in the configuration is `AdamW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0005\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "The learning rate can be easily changed using `trainer.set_lr(new_lr)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  2. The batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. The Pytorch neural network module. We can see that the network is an instance of the class `NetworkWithPriors`. This architecture consists of a multilayer perceptron (MLP) with residual connections, batch normalization layers and GELU activations (`trainer.model.mlp`). An embedding network, here a 1D CNN (`trainer.model.embedding_net`), produces a latent embedding of the input batch of reflectivity curves which is concatenated with the prior bounds for the thin film parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetworkWithPriors(\n",
       "  (embedding_net): ConvEncoder(\n",
       "    (core): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (avpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): ResidualMLP(\n",
       "    (first_layer): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0-1): 2 x BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (condition_layer): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (linear_layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (last_layer): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can control the training process using callback objects, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. `JPlotLoss` - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the `frequency` argument setting the refresh rate of the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. `StepLR` - implements a learning rate scheduler which decreases the learning rate in steps (after a number of iterations defined by `step_size` the learning rate is multiplied by the factor `gamma`). Other types of learning rate schedulers can alternatively be used, such as `CosineAnnealingWithWarmup`, `LogCyclicLR`, `OneCycleLR` or `ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. `SaveBestModel` - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the `freq` argument, the weights of the neural network are saved at the specified `path` if the current average loss (computed over the last `average` iterations) is lower than the loss for the previous save. The history of the losses and learning rate values is also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the package is installed in editable mode, the default save path is relative to the repository directory (defined by the global variable `SAVED_MODELS_DIR`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_name = 'model_' + config_name + '.pt'\n",
    "save_path = str(SAVED_MODELS_DIR / save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the callback objects together in a touple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = (\n",
    "    JPlotLoss(frequency=10), \n",
    "    StepLR(step_size=5000, gamma=0.1, last_epoch=-1), \n",
    "    SaveBestModel(path=save_path, freq=100, average=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The callbacks can also be initialized directly from the configuration file:\n",
    "`callbacks = get_callbacks_by_name(config_name)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training process is initiated by calling the `train` method of the trainer. This method accepts as arguments the previously defined tuple of callbacks, as well as the number of iterations (batches). Notably, a new batch of data is generated at each iteration, the training taking place in a \"one-epoch regime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "trainer.train(num_batches=1000, callbacks=callbacks)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the history of the losses and learning rates can be accessed via `trainer.losses` and `trainer.lrs`. We can also find them together with the model state_dict in the saved dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'lrs', 'losses', 'prev_save', 'batch_num', 'best_loss'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(save_path, weights_only=False).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "The saved weights can be loaded into a compatible neural network (`net`) as:\n",
    "\n",
    "```python\n",
    "saved_dict = torch.load(save_path)\n",
    "model_state_dict = saved_dict['model']\n",
    "net.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model state dictionaries of all the saved '.pt' files in a directory can be further converted to the '.safetensors' format for exporting to Huggingface using the `convert_pt_to_safetensors` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training from the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we described the workflow for training a model in a Jupyter Notebook, where we loaded the trainer from the configuration file but defined the callbacks manually. Alternatively, one can train a model from the terminal (in this case the callbacks defined in the configuration file are used):\n",
    "\n",
    "```bash\n",
    "python -m reflectorch.train config_name\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the YAML configuration for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following we show how the YAML configuration file can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} Sample YAML configuration\n",
    "```yaml\n",
    "\n",
    "general:\n",
    "  name: a_base_point_xray_conv_standard\n",
    "  root_dir: null\n",
    "  \n",
    "dset:\n",
    "  cls: ReflectivityDataLoader\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [1., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [0., 50.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [1.0e-2, 5.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      scale_params_by_ranges: false\n",
    "      scaled_range: [-1., 1.]\n",
    "      device: 'cuda'\n",
    "      \n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      device: 'cuda'\n",
    "      \n",
    "  intensity_noise:\n",
    "    cls: GaussianExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.01, 0.3]\n",
    "      consistent_rel_err: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      add_to_context: true\n",
    "\n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "\n",
    "model:\n",
    "  network:\n",
    "    cls: NetworkWithPriors\n",
    "    pretrained_name: null\n",
    "    device: 'cuda'\n",
    "    kwargs:\n",
    "      embedding_net_type: 'conv'\n",
    "      embedding_net_kwargs:\n",
    "        in_channels: 1\n",
    "        hidden_channels: [32, 64, 128, 256, 512]\n",
    "        kernel_size: 3\n",
    "        dim_embedding: 128\n",
    "        dim_avpool: 1\n",
    "        use_batch_norm: true\n",
    "        use_se: false\n",
    "        activation: 'gelu'\n",
    "      pretrained_embedding_net: null\n",
    "      dim_out: 8\n",
    "      dim_conditioning_params: 0\n",
    "      layer_width: 512\n",
    "      num_blocks: 8\n",
    "      repeats_per_block: 2\n",
    "      residual: true\n",
    "      use_batch_norm: true\n",
    "      use_layer_norm: false\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      conditioning: 'film'\n",
    "      concat_condition_first_layer: false\n",
    "       \n",
    "training:\n",
    "  trainer_cls: PointEstimatorTrainer\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-3\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    train_with_q_input: false\n",
    "    condition_on_q_resolutions: false\n",
    "    rescale_loss_interval_width: true\n",
    "    use_l1_loss: true\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: CosineAnnealingWithWarmup\n",
    "      kwargs:\n",
    "        min_lr: 1.0e-6\n",
    "        warmup_iters: 500\n",
    "        total_iters: 10000\n",
    "\n",
    "  logger:\n",
    "    cls: TensorBoardLogger\n",
    "    kwargs:\n",
    "      log_dir: \"tensorboard_runs/test_1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `general` key, contains the following subkeys:\n",
    "\n",
    "- `name` - name used for saving the model\n",
    "- `root` - path to the root directory, defaults to the package directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "general:\n",
    "  name: a_base_point_xray_conv_standard\n",
    "  root_dir: null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dset` key defines the settings pertaining to the data generation (i.e. the SLD profile parameterization, the ranges of the thin film parameters, the q values, the noise added to the reflectivity curves and the scaling of the reflectivity curves). It has the following subkeys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `cls` (*optional*) - the class of the data loader. If not provided, the default class `ReflectivityDataLoader` is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `prior_sampler` - responsible for defining the type of SLD parameterization, the ranges from which the thin film parameters are sampled and the ranges from which the widths of the prior bounds are sampled. The `SubpriorParametricSampler` class first samples a center (**C**) from the parameter ranges and a width (**W**) from the bound width ranges. This defines a subinterval delimited by the minimum prior bound **B_min** = **C** - **W**/2 and the maximum prior bound **B_max** = **C** + **W**/2. Then, the values of the parameters (to be used for simulating the reflectivity curves and as ground truth) are uniformly sampled within the interval [**B_min**, **B_max**]. It has the following keyword arguments:\n",
    "- `model_name` - name associated with the type of SLD parameterization. Here, `standard_model` represents the standard box model parameterization of the SLD with the parameters thickness, roughness and real layer SLD.\n",
    "- `max_num_layers` - the number of layers in the thin film (in addition to the substrate)\n",
    "- `param_ranges` - the ranges from which the values of each type of thin film parameter are uniformly sampled (for the standard model `thicknesses`, `roughnesses` and `slds`) \n",
    "- `bound_width_ranges` - the ranges from which the prior bound widths of each type of thin film parameter are uniformly sampled. If the argument `logdist` is set to `true`, the prior bound widths are sampled uniformly on a logarithmic scale instead, biasing the training towards smaller prior bound widths.\n",
    "- `constrained_roughness` - if `true` the sampling of the roughness parameters is constrained such that the roughness of an interface between two layers does not exceed a fraction (defined by the argument `max_thickness_share`) of the thickness of either one of those layers.\n",
    "- `max_total_thickness` (optional) - if provided, the sampling is performed such that the sum of the sampled layer thicknesses does not exceed this value\n",
    "- `scale_params_by_ranges` - if `true` the parameters are scaled with respect to their ranges, otherwise they are scaled with respect to their subprior bound interval. The default is `false`.\n",
    "- `scaled_range` - the ML-friendly range to which the parameters (and prior bounds) are scaled to, the default is [-1, 1]\n",
    "- `device` - default is `'cuda'` for GPU use, can be changed to `'cpu'` for CPU use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} FigureReflectometryNetwork.png\n",
    ":scale: 25\n",
    ":align: center\n",
    ":name: figure_reflectometry_network\n",
    "(a) Parameter sampling process (b) Neural network architecture\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  cls: ReflectivityDataLoader\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [1., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [0., 50.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [1.0e-2, 5.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      scale_params_by_ranges: false\n",
    "      scaled_range: [-1., 1.]\n",
    "      device: 'cuda'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `q_generator` - responsible for generating the transfer vector (q) values at which the reflectivity is to be simulated. We must first specifiy its class. The `ConstantQ` class generates a fixed discretization for all the reflectivity curves in the batch. Its `q` keyword argument is a tuple formatted as *[q_min, q_max, num_q_points]*, which defines the minimum q value, the maximum q value as well as the number of points (including the interval boundaries) to be equidistantly sampled. Other q generator classes are available such as `VariableQ` (equidistant grid with variable *q_min*, *q_max* and *num_q_points*, further described in the *Advanced functionality* section) and `ConstantAngle` which generates the grid of q values based on equidistantlly sampled scattering angles and the wavelength of the beam. The `device` argument can be changed to `'cpu'` for CPU use (default is `'cuda'` for GPU use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "dset:\n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      device: 'cuda'\n",
    "      \n",
    "```      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `q_noise` (*optional*) - responsible for adding noise to the generated q values, which emulates possible measurement errors due to sample misalignment. The `BasicQNoiseGenerator` class can add both systematic q shifts (the same change applied to all q points of a curve) and random noise (different changes applied to each q point of a curve) to the q values of the batch of curves, it has the following arguments:\n",
    "- `shift_std` - the standard deviation of the normal distribution for sampling the systematic q shifts (one value sampled per curve in the batch)\n",
    "- `noise_std` - the standard deviation of the normal distribution for sampling the random q noise (one value sampled per point in the curve). The standard deviation is the same for all curves in the batch if provided as a float, or uniformly sampled from a range for each curve in the batch if provided as a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. `intensity_noise` - responsible for adding noise to the intensity values of the reflectivity curves.\n",
    "\n",
    "    The `GaussianExpIntensityNoise` combines three types of noise:\n",
    "    - Gaussian noise: Applies Gaussian noise to account for count-based Poisson noise as well as other sources of error.\n",
    "    - Shift noise: Applies a multiplicative scaling to the curves, equivalent to a vertical shift in logarithmic space.\n",
    "    - Background noise: Adds a constant background to the curves.\n",
    "\n",
    "    It has the following arguments:\n",
    "    - `relative_errors` - range of relative errors for Gaussian noise.\n",
    "    - `consistent_rel_err` - if `true`, uses a consistent relative error for Gaussian noise across all points in a curve.\n",
    "    - `apply_shift` - if `true`, applies shift noise to the curves.\n",
    "    - `shift_range` - range of shift factors for shift noise.\n",
    "    - `apply_background` - if `true`, applies background noise to the curves.\n",
    "    - `background_range` - range for background values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "intensity_noise:\n",
    "  cls: GaussianExpIntensityNoise\n",
    "  kwargs:\n",
    "    relative_errors: [0.01, 0.3]\n",
    "    consistent_rel_err: false\n",
    "    apply_shift: true\n",
    "    shift_range: [-0.3, 0.3]\n",
    "    apply_background: false\n",
    "    background_range: [1.0e-10, 1.0e-4]\n",
    "    add_to_context: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. `smearing` (*optional*) - responsible for adding resolution smearing to the curves (which can occur in neutron experiments due to uncertainties in incident angle  or wavelength). The intensity at a q point will be the average of the intensities of neighbouring q points, weighted by a gaussian profile. The arguments of the `Smearing` class are:\n",
    "- `sigma_range` - the range for sampling the resolutions\n",
    "- `constant_dq` - if `True` the smearing is constant (the resolution is given by the constant dq at each point in the curve, i.e. x-ray variant), otherwise the smearing is linear (the resolution is given by the constant dq/q at each point in the curve, i.e. neutron variant)\n",
    "- `gauss_num` - the number of points used to define the Gaussian smearing kernel. A higher number increases precision at the cost of computational efficiency.\n",
    "- `share_smeared` - the share of curves in the batch for which the resolution smearing is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:   \n",
    "  smearing:\n",
    "    cls: Smearing\n",
    "    kwargs:\n",
    "      sigma_range: [0.01, 0.08]\n",
    "      constant_dq: False\n",
    "      gauss_num: 17\n",
    "      share_smeared: 0.8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. `curves_scaler` - responsible for scaling the reflectivity curves to a ML-friendly range. The `LogAffineCurvesScaler` class scales the reflectivity curves (R) accoring to the formula: \n",
    "\n",
    "$R_{scaled} = log_{10}(R + eps) \\times weight + bias$\n",
    "\n",
    "The argument `eps` sets the minimum intensity value of the reflectivity curves which is considered. The default values of 1.0e-10 for `eps`, 0.2 for `weight` and 1.0 for `bias` results in the interval [-1, 1] for the scaled reflectivity curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:    \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` key defines the neural network architecture. Its `network` subkey contains the following subkeys:\n",
    "\n",
    "- `cls` - the class of the neural network\n",
    "- `pretrained_name` - the name of a pretrained model used to initialize the weights (optional)\n",
    "- `device` - the Pytorch device (either `cuda` or `cpu`)\n",
    "- `kwargs` - the keyword arguments for the provided class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NetworkWithPriors` class has the following keyword arguments:\n",
    "- `embedding_net_type` - the type of embedding network (e.g. `'conv'` for a 1D CNN, `'fno'` for a FNO)\n",
    "- `embedding_net_kwargs` - the keyword arguments corresponding to the chosen embedding network (e.g. for the 1D CNN: `in_channels` - the number of input channels of the 1D CNN, `hidden_channels` - list with the number of channels for each layer of the 1D CNN, `dim_embedding` - the dimension of the embedding produced by the 1D CNN, `dim_avpool` - the output size of the adaptive average pooling layer, `activation` - the type of activation function in the 1D CNN)\n",
    "- `pretrained_embedding_net` - the path to the weights of a pretrained embedding network (optional)\n",
    "- `dim_out` - the dimension of the output produced by the MLP (i.e. the number of thin film parameters to be predicted)\n",
    "- `dim_conditioning_params` - the dimension of extra parameters used as input to the network in specific training scenarios (such as the resolution coefficient dq/q), defaults to 0.\n",
    "- `layer_width` - the width (i.e. number of neurons) of a linear layer in the MLP\n",
    "- `num_blocks` - the number of residual blocks in the MLP\n",
    "- `repeats_per_block` - the number of normalization/activation/linear repeats in a block\n",
    "- `use_batch_norm` - whether to use batch normalization in the MLP\n",
    "- `use_layer_norm` - whether to use layer normalization in the MLP (if batch normalization is not used)\n",
    "- `mlp_activation` - the type of activation function in the MLP\n",
    "- `dropout_rate` - dropout rate for each block\n",
    "- `conditioning` - the modality in which the prior bounds are provided to the network, either by concatenating the prior bounds to the data embedding ( `'concat'`) before the MLP or by modulating the intermediated features in each block of the MLP via [FiLM](https://arxiv.org/abs/1709.07871) layers (`'film'`) or [GLU](https://pytorch.org/docs/stable/generated/torch.nn.GLU.html) layers (`'glu'`). If `concat_condition_first_layer` is `true`, the concatenation is performed even when `'film'` or `'glu'` are used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "\n",
    "model:\n",
    "  network:\n",
    "    cls: NetworkWithPriors\n",
    "    pretrained_name: null\n",
    "    device: 'cuda'\n",
    "    kwargs:\n",
    "      embedding_net_type: 'conv'\n",
    "      embedding_net_kwargs:\n",
    "        in_channels: 1\n",
    "        hidden_channels: [32, 64, 128, 256, 512]\n",
    "        kernel_size: 3\n",
    "        dim_embedding: 128\n",
    "        dim_avpool: 1\n",
    "        use_batch_norm: true\n",
    "        activation: 'gelu'\n",
    "      pretrained_embedding_net: null\n",
    "      dim_out: 8\n",
    "      dim_conditioning_params: 0\n",
    "      layer_width: 512\n",
    "      num_blocks: 8\n",
    "      repeats_per_block: 2\n",
    "      residual: true\n",
    "      use_batch_norm: true\n",
    "      use_layer_norm: false\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      conditioning: 'film' # 'concat', 'glu', 'film'\n",
    "      concat_condition_first_layer: false\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` key can be used to customize the training settings:\n",
    "\n",
    "- `trainer_cls` - the class of the trainer (by default `PointEstimatorTrainer`)\n",
    "- `num_iterations` - the total number of training iterations\n",
    "- `batch_size` - the batch size (number of curves generated at each iteration)\n",
    "- `lr` - the initial learning rate\n",
    "- `grad_accumulation_steps` - if larger than 1, training is performed using gradient accumulation with the chosen number of steps\n",
    "- `clip_grad_norm_max` - the maximum norm for gradient clipping (optional)\n",
    "- `update_tqdm_freq` - the frequency for updating the [tqdm progress bar](https://tqdm.github.io/)\n",
    "- `optimizer` - the used [Pytorch optimizer](https://pytorch.org/docs/stable/optim). Default is `AdamW`\n",
    "- `trainer_kwargs` - additional trainer keyword arguments. Can be used to specify optional inputs to the network, such as the q values (`train_with_q_input`) or the resolution coefficient (`condition_on_q_resolutions`). Can also be used for setting the optimizer keyword arguments (`optim_kwargs`).\n",
    "- `callbacks` - (optional) the callback classes together with their keyword arguments.\n",
    "- `logger` - (optional) a Tensorboard logger for monitoring the progress of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "training:\n",
    "  trainer_cls: PointEstimatorTrainer\n",
    "  num_iterations: 100000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-3\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    train_with_q_input: false\n",
    "    condition_on_q_resolutions: false\n",
    "    rescale_loss_interval_width: true\n",
    "    use_l1_loss: true\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 20000\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    cls: TensorBoardLogger\n",
    "    kwargs:\n",
    "      log_dir: \"tensorboard_runs/test_1\"\n",
    "     \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
