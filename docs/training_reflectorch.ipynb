{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary methods from the `reflectorch` package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from reflectorch import SAVED_MODELS_DIR, SaveBestModel, StepLR, get_trainer_by_name, get_callbacks_by_name\n",
    "from reflectorch.extensions.jupyter import JPlotLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "Alternatively, we can import everything from reflectorch with\n",
    "`from reflectorch import *`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model we use the `Trainer` class, which contains all the components necessary training process such as the data generator, the neural network and the optimizer.\n",
    "\n",
    " We can initialize the trainer according to the specifications defined in a YAML configuration file using the `get_trainer_by_name` method which takes as input the name of the configuration file. If the package was installed in editable model, the configuration files are read from the `configs` directory located inside the repository, otherwise the path to the directory containing the configuration file should also be specified using the `config_dir` argument. The `load_weights` argument should be set to `False` since we want the neural network weights to be randomly initialized for a fresh training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model c1 loaded. Number of parameters: 3.83 M\n"
     ]
    }
   ],
   "source": [
    "config_name = 'c1'\n",
    "trainer = get_trainer_by_name(config_name, load_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The trainer contains several important attributes we can inspect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. The Pytorch optimizer. We can observe that the optimizer specified in the configuration is `AdamW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0005\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "The learning rate can be easily changed using `trainer.set_lr(new_lr)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  2. The batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. The Pytorch neural network module. We can see that the network is an instance of the class `PriorInformedNetworkConvEmb`. This architecture consists of a multilayer perceptron (MLP) with residual connections, batch normalization layers and GELU activations (`trainer.model.mlp`). A 1D CNN embedding network (`trainer.model.embedding_net`) produces a latent embedding of the input batch of reflectivity curves which is concatenated with the prior bounds for the thin film parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriorInformedNetworkConvEmb(\n",
       "  (embedding_net): ConvEncoder(\n",
       "    (core): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (avpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): ResidualMLP(\n",
       "    (first_layer): Linear(in_features=144, out_features=512, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0-1): 2 x BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (last_layer): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add functionality to the training process using callback objects, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. `JPlotLoss` - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the `frequency` argument setting the refresh rate of the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. `StepLR` - implements a learning rate scheduler which decreases the learning rate in steps (after a number of iterations defined by `step_size` the learning rate is multiplied by the factor `gamma`). Other types of learning rate schedulers can alternatively be used, such as `CyclicLR`, `LogCyclicLR`, `OneCycleLR` or `ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. `SaveBestModel` - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the `freq` argument, the weights of the neural network are saved at the specified `path` if the current average loss (computed over the last `average` iterations) is lower than the loss for the previous save. The history of the losses and learning rate values is also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the package is installed in editable mode, the default save path is relative to the repository directory (defined by the global variable `SAVED_MODELS_DIR`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_name = 'model_' + config_name + '.pt'\n",
    "save_path = str(SAVED_MODELS_DIR / save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the callback objects together in a touple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = (\n",
    "    JPlotLoss(frequency=10), \n",
    "    StepLR(step_size=5000, gamma=0.1, last_epoch=-1), \n",
    "    SaveBestModel(path=save_path, freq=100, average=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The callbacks can also be initialized directly from the configuration file:\n",
    "`callbacks = get_callbacks_by_name(config_name)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training process is initiated by invoking the `train` method of the trainer. This method accepts as arguments the previously defined tuple of callbacks, as well as the number of iterations (batches). Notably, a new batch of data is generated at each iteration, the training taking place in a \"one-epoch regime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "trainer.train(num_batches=1000, callbacks=callbacks)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the history of the losses and learning rates can be accessed via `trainer.losses` and `trainer.lrs`. We can also find them together with the model state_dict in the saved dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'lrs', 'losses', 'prev_save', 'batch_num', 'best_loss'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(save_path).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "The saved weights can be loaded into a compatible neural network (`net`) as:\n",
    "\n",
    "```python\n",
    "saved_dict = torch.load(save_path)\n",
    "model_state_dict = saved_dict['model']\n",
    "net.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the YAML configuration for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following we show how the YAML configuration file can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} Sample YAML configuration\n",
    "```yaml\n",
    "\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "  \n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [0., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [-25., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      \n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      \n",
    "  intensity_noise:\n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      apply_scaling: true\n",
    "      scale_range: [-0.02, 0.02]\n",
    "\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3]\n",
    "      \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "       \n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `general` key, contains the following subkeys:\n",
    "\n",
    "- `name` - name used for saving the model\n",
    "- `root` - path to the root directory, defaults to the package directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dset` key defines the settings pertaining to the data generation (i.e. the SLD profile parameterization, the ranges of the thin film parameters, the q values, the noise added to the reflectivity curves and the scaling of the reflectivity curves). It has the following subkeys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `prior_sampler` - responsible for defining the type of SLD parameterization, the ranges on which the thin film parameters are sampled and the ranges on which the widths of the prior bounds are sampled. The `SubpriorParametricSampler` class first samples a center (**C**) from the parameter ranges and a width (**W**) from the bound width ranges. This defines a subinterval delimited by the minimum prior bound **B_min** = **C** - **W**/2 and the maximum prior bound **B_max** = **C** + **W**/2. Then, the values of the parameters (to be used for simulating the reflectivity curves and as ground truth) are uniformly sampled within the interval [**B_min**, **B_max**]. It has the following keyword arguments:\n",
    "- `model_name` - name associated with the type of SLD parameterization. Here, `standard_model` represents the standard box model parameterization of the SLD with the parameters thickness, roughness and real layer SLD.\n",
    "- `max_num_layers` - the number of layers in the thin film (in addition to the substrate)\n",
    "- `param_ranges` - the ranges from which the values of each type of thin film parameter are uniformly sampled (for the standard model `thicknesses`, `roughnesses` and `slds`) \n",
    "- `bound_width_ranges` - the ranges from which the prior bound widths of each type of thin film parameter are uniformly sampled. If the argument `logdist` is set to `true`, the prior bound widths are sampled uniformly on a logarithmic scale instead, biasing the training towards smaller prior bound widths.\n",
    "- `constrained_roughness` - if `true` the sampling of the roughness parameters is constrained such that the roughness of an interface between two layers does not exceed a fraction (defined by the argument `max_thickness_share`) of the thickness of either one of those layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} FigureReflectometryNetwork.png\n",
    ":scale: 25\n",
    ":align: center\n",
    ":name: figure_reflectometry_network\n",
    "Parameter sampling process\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [0., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [-25., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `q_generator` - responsible for generating the transfer vector (q) values at which the reflectivity is to be simulated. We must first specifiy its class. The `ConstantQ` class generates a fixed discretization for all the reflectivity curves in the batch. Its `q` keyword argument is a tuple formatted as *[q_min, q_max, num_q_points]*, which defines the minimum q value, the maximum q value as well as the number of points (including the interval boundaries) to be equidistantlly sampled. Other q generator classes are available such as `VariableQ` (equidistant grid with variable *q_min*, *q_max* and *num_q_points*, further described in the *Advanced functionality* section) and `ConstantAngle` which generates the grid of q values based on equidistantlly sampled scattering angles and the wavelength of the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "dset:\n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      \n",
    "```      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `q_noise` - responsible for adding noise to the generated q values, which emulates possible measurement errors due to sample misalignment. The `BasicQNoiseGenerator` class can add both systematic q shifts (the same change applied to all q points of a curve) and random noise (different changes applied to each q point of a curve) to the q values of the batch of curves, it has the following arguments:\n",
    "- `shift_std` - the standard deviation of the normal distribution for sampling the systematic q shifts (one value sampled per curve in the batch)\n",
    "- `noise_std` - the standard deviation of the normal distribution for sampling the random q noise (one value sampled per point in the curve). The standard deviation is the same for all curves in the batch if provided as a float, or uniformly sampled from a range for each curve in the batch if provided as a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `intensity_noise` - responsible for adding noise to the reflectivity curves. The `BasicExpIntensityNoise` class has the following arguments:\n",
    "- `relative_errors` - the interval the relative errors are uniformly sampled from\n",
    "- `abs_errors` - absolute error for each curve\n",
    "- `logdist` - if `true` the relative errors are sampled uniformly on a logarithmic scale from the interval defined by `relative_errors`\n",
    "- `apply_shift` - if `true` the entire curve is shifted by a value sampled from the interval defined by the `shift_range` argument\n",
    "- `apply_scaling` - if `true` the entire curve is scaled by a value sampled from the interval defined by the `scale_range` argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:   \n",
    "  intensity_noise:\n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      apply_scaling: true\n",
    "      scale_range: [-0.02, 0.02]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. `curves_scaler` - responsible for scaling the reflectivity curves to a ML-friendly range. The `LogAffineCurvesScaler`scales the reflectivity curves (**R**) accoring to the formula: log10(**R** + `eps`) * `weight` + `bias`. The argument `eps` sets the minimum intensity value of the reflectivity curves which is considered. The default values of 1.0e-10 for `eps`, 0.2 for `weight` and 1.0 for `bias` results in the interval [-1, 1] for the scaled reflectivity curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:    \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` key defines the neural network architecture. Its `encoder` subkey (--*obsolete, to be refractored*--), contains the following subkeys:\n",
    "\n",
    "- `cls` - the class of the neural network\n",
    "- `pretrained_name` - the name of a pretrained model used to initialize the weights (optional)\n",
    "- `kwargs` - the keyword arguments for the provided class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PriorInformedNetworkConvEmb` class has the following keyword arguments:\n",
    "- `in_channels` - the number of input channels of the 1D CNN (1 for reflectivity curves)\n",
    "- `hidden_channels` - list with the number of channels for each layer of the 1D CNN\n",
    "- `dim_embedding` - the dimension of the embedding produced by the 1D CNN\n",
    "- `dim_avpool` - the output size of the adaptive average pooling layer (it scales the input size of the linear layer which produces the embedding as avpool * hidden_dims[-1])\n",
    "- `embedding_net_activation` - the type of activation function in the 1D CNN\n",
    "- `use_batch_norm` - whether to use batch normalization (in both the 1D CNN and the MLP)\n",
    "- `dim_out` - the dimension of the output produced by the MLP (i.e. the number of thin film parameters to be predicted)\n",
    "- `layer_width` - the width (i.e. number of neurons) of a linear layer in the MLP\n",
    "- `num_blocks` - the number of residual blocks in the MLP\n",
    "- `repeats_per_block` - the number of normalization/activation/linear repeats in a block\n",
    "- `mlp_activation` - the type of activation function in the MLP\n",
    "- `dropout_rate` - dropout rate for each block\n",
    "- `pretrained_embedding_net` - the name of a pretrained model used to initialize the weights of the 1D CNN (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` key can be used to customize the training settings:\n",
    "\n",
    "- `num_iterations` - the total number of training iterations\n",
    "- `batch_size` - the batch size (number of curves generated at each iteration)\n",
    "- `lr` - the initial learning rate\n",
    "- `grad_accumulation_steps` - if larger than 1, training is performed using gradient accumulation with the chosen number of steps\n",
    "- `clip_grad_norm_max` - the maximum norm for gradient clipping (optional)\n",
    "- `train_with_q_input` - must be set to `True` if the q-values are also used as input (i.e. when the FNO embedding network is used)\n",
    "- `update_tqdm_freq` - the frequency for updating the [tqdm progress bar](https://tqdm.github.io/)\n",
    "- `optimizer` - the used [Pytorch optimizer](https://pytorch.org/docs/stable/optim). Default is `AdamW`\n",
    "- `trainer_kwargs` - additional trainer keyword arguments, can be used for setting the optimizer keyword arguments (`optim_kwargs`)\n",
    "- `callbacks` - (optional) the callback classes together with their keyword arguments. Can also be defined directly as illustrated in the previous subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "        \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
