{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary methods from the `reflectorch` package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from reflectorch import SAVED_MODELS_DIR, SaveBestModel, StepLR, get_trainer_by_name, get_callbacks_by_name\n",
    "from reflectorch.extensions.jupyter import JPlotLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "Alternatively, we can import everything from reflectorch with\n",
    "`from reflectorch import *`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model we use the `Trainer` class, which contains all the components necessary training process such as the data generator, the neural network and the optimizer.\n",
    "\n",
    " We can initialize the trainer according to the specifications defined in a YAML configuration file using the `get_trainer_by_name` method which takes as input the name of the configuration file. If the package was installed in editable model, the configuration files are read from the `configs` directory located inside the repository, otherwise the path to the directory containing the configuration file should also be specified using the `config_dir` argument. The `load_weights` argument should be set to `False` since we want the neural network weights to be randomly initialized for a fresh training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model c1 loaded. Number of parameters: 3.83 M\n"
     ]
    }
   ],
   "source": [
    "config_name = 'c1'\n",
    "trainer = get_trainer_by_name(config_name, load_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The trainer contains several important attributes we can inspect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. The Pytorch optimizer. We can observe that the optimizer specified in the configuration is `AdamW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0005\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "The learning rate can be easily changed using `trainer.set_lr(new_lr)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  2. The batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. The Pytorch neural network module. We can see that the network is an instance of the class `PriorInformedNetworkConvEmb`. This architecture consists of a multilayer perceptron (MLP) with residual connections, batch normalization layers and GELU activations (`trainer.model.mlp`). A 1D CNN embedding network (`trainer.model.embedding_net`) produces a latent embedding of the input batch of reflectivity curves which is concatenated with the prior bounds for the thin film parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriorInformedNetworkConvEmb(\n",
       "  (embedding_net): ConvEncoder(\n",
       "    (core): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (avpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): ResidualMLP(\n",
       "    (first_layer): Linear(in_features=144, out_features=512, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0-1): 2 x BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (last_layer): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add functionality to the training process using callback objects, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. `JPlotLoss` - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the `frequency` argument setting the refresh rate of the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. `StepLR` - implements a learning rate scheduler which decreases the learning rate in steps (after a number of iterations defined by `step_size` the learning rate is multiplied by the factor `gamma`). Other types of learning rate schedulers can alternatively be used, such as `CyclicLR`, `LogCyclicLR`, `OneCycleLR` or `ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. `SaveBestModel` - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the `freq` argument, the weights of the neural network are saved at the specified `path` if the current average loss (computed over the last `average` iterations) is lower than the loss for the previous save. The history of the losses and learning rate values is also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the package is installed in editable mode, the default save path is relative to the repository directory (defined by the global variable `SAVED_MODELS_DIR`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_name = 'model_' + config_name + '.pt'\n",
    "save_path = str(SAVED_MODELS_DIR / save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the callback objects together in a touple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = (\n",
    "    JPlotLoss(frequency=10), \n",
    "    StepLR(step_size=5000, gamma=0.1, last_epoch=-1), \n",
    "    SaveBestModel(path=save_path, freq=100, average=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The callbacks can also be initialized directly from the configuration file:\n",
    "`callbacks = get_callbacks_by_name(config_name)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training process is initiated by invoking the `train` method of the trainer. This method accepts as arguments the previously defined tuple of callbacks, as well as the number of iterations (batches). Notably, a new batch of data is generated at each iteration, the training taking place in a \"one-epoch regime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "trainer.train(num_batches=1000, callbacks=callbacks)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainer.train(num_batches=10000, callbacks=callbacks)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"trainer.train(num_batches=10000, callbacks=callbacks)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the history of the losses and learning rates can be accessed via `trainer.losses` and `trainer.lrs`. We can also find them together with the model state_dict in the saved dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'lrs', 'losses', 'prev_save', 'batch_num', 'best_loss'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(save_path).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "The saved weights can be loaded into a compatible neural network (`net`) as:\n",
    "\n",
    "```python\n",
    "saved_dict = torch.load(save_path)\n",
    "model_state_dict = saved_dict['model']\n",
    "net.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from reflectorch import OneCycleLR, CyclicLR, LogCyclicLR\\n\\ncallbacks = (\\n    JPlotLoss(frequency=10), \\n    LogCyclicLR(base_lr=1e-5, max_lr=1e-3, period=100, start_period=40, gamma=0.5), \\n    SaveBestModel(path=save_path, freq=100, average=10),\\n)\\n\\ntrainer.set_lr(1e-7)\\ntrainer.train(num_batches=300, callbacks=callbacks) '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from reflectorch import OneCycleLR, CyclicLR, LogCyclicLR\n",
    "\n",
    "callbacks = (\n",
    "    JPlotLoss(frequency=10), \n",
    "    LogCyclicLR(base_lr=1e-5, max_lr=1e-3, period=100, start_period=40, gamma=0.5), \n",
    "    SaveBestModel(path=save_path, freq=100, average=10),\n",
    ")\n",
    "\n",
    "trainer.set_lr(1e-7)\n",
    "trainer.train(num_batches=300, callbacks=callbacks) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fig, ax = plt.subplots(figsize=(6,6))\\n\\nax.semilogy(trainer.lrs) '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.semilogy(trainer.lrs) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the YAML configuration for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following we show how the YAML configuration file can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} Sample YAML configuration\n",
    "```yaml\n",
    "\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "  \n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [0., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [-25., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      \n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      remove_zero: false\n",
    "      fixed_zero: true\n",
    "      \n",
    "  intensity_noise:\n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      apply_scaling: true\n",
    "      scale_range: [-0.02, 0.02]\n",
    "\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3] #[0., 1.0e-3]\n",
    "      \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "       \n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `general` key, contains the following subkeys:\n",
    "\n",
    "- `name` - name used for saving the model\n",
    "- `root` - path to the root directory, defaults to the package directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` key defines the neural network architecture. Its `encoder` subkey, contains the following subkeys:\n",
    "\n",
    "- `cls` - the class of the neural network\n",
    "- `pretrained_name` - the name of a pretrained model used to initialize the weights (optional)\n",
    "- `kwargs` - the keyword arguments for the provided class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PriorInformedNetworkConvEmb` class has the following keyword arguments:\n",
    "- `in_channels` - the number of input channels of the 1D CNN (1 for reflectivity curves)\n",
    "- `hidden_channels` - list with the number of channels for each layer of the 1D CNN\n",
    "- `dim_embedding` - the dimension of the embedding produced by the 1D CNN\n",
    "- `dim_avpool` - the output size of the adaptive average pooling layer (it scales the input size of the linear layer which produces the embedding as avpool * hidden_dims[-1])\n",
    "- `embedding_net_activation` - the type of activation function in the 1D CNN\n",
    "- `use_batch_norm` - whether to use batch normalization (in both the 1D CNN and the MLP)\n",
    "- `dim_out` - the dimension of the output produced by the MLP (i.e. the number of thin film parameters to be predicted)\n",
    "- `layer_width` - the width (i.e. number of neurons) of a linear layer in the MLP\n",
    "- `num_blocks` - the number of residual blocks in the MLP\n",
    "- `repeats_per_block` - the number of normalization/activation/linear repeats in a block\n",
    "- `mlp_activation` - the type of activation function in the MLP\n",
    "- `dropout_rate` - dropout rate for each block\n",
    "- `pretrained_embedding_net` - the name of a pretrained model used to initialize the weights of the 1D CNN (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` key can be used to customize the training settings:\n",
    "\n",
    "- `num_iterations` - the total number of training iterations\n",
    "- `batch_size` - the batch size (number of curves generated at each iteration)\n",
    "- `lr` - the initial learning rate\n",
    "- `grad_accumulation_steps` - if larger than 1, training is performed using gradient accumulation with the chosen number of steps\n",
    "- `clip_grad_norm_max` - the maximum norm for gradient clipping (optional)\n",
    "- `train_with_q_input` - must be set to `True` if the q-values are also used as input (i.e. when the FNO embedding network is used)\n",
    "- `update_tqdm_freq` - the frequency for updating the [tqdm progress bar](https://tqdm.github.io/)\n",
    "- `optimizer` - the used [Pytorch optimizer](https://pytorch.org/docs/stable/optim). Default is `AdamW`\n",
    "- `trainer_kwargs` - additional trainer keyword arguments, can be used for setting the optimizer keyword arguments (`optim_kwargs`)\n",
    "- `callbacks` - (optional) the callback classes together with their keyword arguments. Can also be defined directly as illustrated in the previous subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "        \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
