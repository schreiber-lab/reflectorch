{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary methods from the reflectorch package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reflectorch import get_trainer_by_name, SAVED_MODELS_DIR, StepLR, SaveBestModel\n",
    "from reflectorch.extensions.jupyter import JPlotLoss\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "Alternatively, we can import everything from reflectorch with\n",
    "from reflectorch import *\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Trainer* class is the central object for the training process, which encapsulates the simulation of the training data as well as the neural network architecture. We can initialize the trainer according to the specifications defined in a YAML configuration file using the *get_trainer_by_name* method which takes as input the name of the configuration file. The `load_weights` parameter should be set to `False` since we want the neural network weights to be randomly initialized for a fresh training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model time_val_sim_L5_q256_d300_r60_s25_bs4_budist_noise-poisson02_LONGER loaded. Number of parameters: 13.85 M\n"
     ]
    }
   ],
   "source": [
    "config_name = 'time_val_sim_L5_q256_d300_r60_s25_bs4_budist_noise-poisson02_LONGER'\n",
    "trainer = get_trainer_by_name(config_name, load_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The trainer contains several important attributes which we can access:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. The Pytorch optimizer. We can observe that the optimizer specified in the configuration is AdamW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "The learning rate can be easily changed using trainer.set_lr(new_lr)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  2. The batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. The neural network architecture. We see that the model belongs to the class *SubPriorConvFCEncoder_V2*, which contains a 1D CNN embedding network and a multilayer perceptron (MLP) with residual connection, batch normalization layers and GELU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubPriorConvFCEncoder_V2(\n",
       "  (conv): ConvEncoder(\n",
       "    (core): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (avpool): AdaptiveAvgPool1d(output_size=8)\n",
       "    (fc): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): ResidualNet(\n",
       "    (initial_layer): Linear(in_features=162, out_features=1024, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm1d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layer): Linear(in_features=1024, out_features=17, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inquire the the location of the directory where the models are saved using the *SAVED_MODELS_DIR* global variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/vmunteanu/Jupyter Notebooks/Reflectivity/reflectorch/saved_models')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we should create a name used for saving the weights of our model during training, which together with the directory defines the *save_path*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_name = 'model_' + config_name + '.pt'\n",
    "save_path = str(SAVED_MODELS_DIR / save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add functionality to the training process using several callbacks, which are grouped together in a Python touple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = (\n",
    "    JPlotLoss(frequency=10, ), \n",
    "    StepLR(step_size=5000, gamma=0.1, last_epoch=-1), \n",
    "    SaveBestModel(path=save_path, freq=100, )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The callbacks defined above provide the following functionality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. JPlotLoss - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the *frequency* parameter being the refresh rate of the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. StepLR - implements a learning rate scheduler which decreases the learning rate in steps. After a number of iterations defined by *step_size* the learning rate is multiplied with the factor *gamma*. Other types of learning rate schedulers can alternatively be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. SaveBestModel - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the *freq* parameter, the weights of the neural network are saved at the specified *path* if the current value of the loss is lower than the loss for the previous save. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training process is started by calling the *train_epoch* method of the trainer. This method takes as parameters the previously define tuple of callbacks as well as the number of batches / iterations. Notably a new batch of data is generated at each iteration, the training taking place in a \"one-epoch regime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    trainer.train_epoch(num_batches=15000, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](training_curve_reflectorch_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the YAML configuration for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following we show how the YAML configuration can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown}\n",
    "\n",
    "general:\n",
    "  name: val_sim_L2_q256_d300_r60_s25_bs4_budist_noise-poisson02\n",
    "  root_dir: null\n",
    "  \n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [1., 300.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [0., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 300.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      \n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.3, 256]\n",
    "      remove_zero: false\n",
    "      fixed_zero: true\n",
    "      \n",
    "\n",
    "  intensity_noise: \n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: false\n",
    "      shift_range: [-0.001, 0.001]\n",
    "      apply_scaling: false\n",
    "      scale_range: [-0.001, 0.001]\n",
    "\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-7\n",
    "      noise_std: [0., 1.0e-6]\n",
    "      \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2 #0.2\n",
    "      bias: 1.0 #1.0\n",
    "      eps: 1.0e-10\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: SubPriorConvFCEncoder_V2\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "       hidden_dims: [32, 64, 128, 256, 512]\n",
    "       latent_dim: 8\n",
    "       conv_latent_dim: 128\n",
    "       avpool: 8\n",
    "       use_batch_norm: true\n",
    "       in_features: 256\n",
    "       prior_in_features: 16\n",
    "       hidden_features: 1024\n",
    "       num_blocks: 6  #3\n",
    "       fc_activation: 'gelu'\n",
    "       conv_activation: 'gelu' #'lrelu'\n",
    "       pass_bounds: false\n",
    "       pretrained_conv: null\n",
    "training:\n",
    "  train_with_q_input: False\n",
    "  num_iterations: 2000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  update_tqdm_freq: 1\n",
    "  grad_accumulation_steps: 1\n",
    "  optimizer: AdamW\n",
    "\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `general` key, contains the following lower level keys:\n",
    "\n",
    "- `name` - which should be set to the name of the particular model / configuration file\n",
    "- `root` - for providing the path to the root directory, default is the current directory (`null`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "general:\n",
    "  name: val_sim_L2_q256_d300_r60_s25_bs4_budist_noise-poisson02\n",
    "  root_dir: null\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: SubPriorConvFCEncoder_V2\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "       hidden_dims: [32, 64, 128, 256, 512]\n",
    "       latent_dim: 8\n",
    "       conv_latent_dim: 128\n",
    "       avpool: 8\n",
    "       use_batch_norm: true\n",
    "       in_features: 256\n",
    "       prior_in_features: 16\n",
    "       hidden_features: 1024\n",
    "       num_blocks: 6  #3\n",
    "       fc_activation: 'gelu'\n",
    "       conv_activation: 'gelu'\n",
    "       pass_bounds: false\n",
    "       pretrained_conv: null\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` key can be used to customize the training settings:\n",
    "\n",
    "- `num_iterations` - the total number of iterations the network is trained for\n",
    "- `batch_size` - the batch size (number of curves generated at each iteration)\n",
    "- `optimizer` - the used [Pytorch optimizer](https://pytorch.org/docs/stable/optim). Default is `AdamW`\n",
    "- `lr` - the initial learning rate\n",
    "- `grad_accumulation_steps` - if larger than 1, training is performed with gradient accumulation with the chosen number of steps\n",
    "\n",
    "- `update_tqdm_freq` - the frequency for updating the [tqdm progress bar](https://tqdm.github.io/)\n",
    "- `train_with_q_input` - must be set to `True` if the q-values are used as input (i.e. when the )\n",
    "- `callbacks` - (optional) the callback classes together with their arguments. Can also be defined directly as in the previous subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "training:\n",
    "  train_with_q_input: False\n",
    "  num_iterations: 2000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  update_tqdm_freq: 1\n",
    "  grad_accumulation_steps: 1\n",
    "  optimizer: AdamW\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "        \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
