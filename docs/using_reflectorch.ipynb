{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using a trained reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is importing the necessary methods from the reflectorch package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f419af6f7d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import widgets, interact\n",
    "from reflectorch import get_trainer_by_name\n",
    "\n",
    "torch.manual_seed(0) # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to import a trained reflectorch model, we first have to specifiy the name of the trained model we wish to load. This name should match the name of the YAML configuration file used for training that model. Here we load a model for a 2-layer box parameterization of the thin film SLD profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model_name = 'time_val_exp_L2_q128-015_d500_r60_s25n_bs4_budist_noise-poisson02-sh03-sc002-qs1e3-qn1e3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize an instance of the `PointEstimatorTrainer` class using the `get_trainer_by_name` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{warning}\n",
    "The `load_weights` argument must be set to `True` in order for the saved weights of the neural network to be loaded, otherwise the network weights are randomly initialized.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model time_val_exp_L2_q128-015_d500_r60_s25n_bs4_budist_noise-poisson02-sh03-sc002-qs1e3-qn1e3 loaded. Number of parameters: 13.37 M\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer_by_name(model_name=trained_model_name, load_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a batch of simulated data using the `get_batch` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "simulated_data = trainer.loader.get_batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a dictionary with 4 components indexed by the following keys:\n",
    "\n",
    " 1. **params** - an instance of the `ParametricParams` class constaining the original values of the generated sample parameters, the generated minimum prior bound for each parameter and the generated maximum prior bound for each parameter (see the [paper](https://doi.org/10.1107/S1600576724002115) for more details about the generation process)\n",
    " 2. **scaled_params** - a Pytorch Tensor containing the parameters, minimum bounds and maximum bounds, all scaled to the ML-friendly range [-1, 1]\n",
    " 3. **q_values** - a Pytorch Tensor containing the reciprocal space (q) positions of the points in the reflectivity curve, in units of Å<sup>-1</sup>\n",
    " 4. **scaled_noisy_curves** - a Pytroch Tensor containing the simulated reflectivity curves (including added noise) scaled to the ML-friendly range [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect some of the (scaled) simulated curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8e5d2ffd74f70a0737c6845af05c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = simulated_data['q_values']\n",
    "scaled_noisy_curves = simulated_data['scaled_noisy_curves']\n",
    "unscaled_noisy_curves = trainer.loader.curves_scaler.restore(scaled_noisy_curves)\n",
    "\n",
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlabel('q [$Å^{-1}$]', fontsize=24)\n",
    "    ax.set_ylabel('R$_{scaled}$ (q)', fontsize=24)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        \n",
    "    ax.scatter(q[i].cpu().numpy(), scaled_noisy_curves[i].cpu().numpy(), c='blue', s=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that this trained model corresponds to a 2 layers (*on top of the substrate*) parameterization of the SLD profile, which corresponds to 8 predicted film parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 2,  Number of film parameters: 8\n"
     ]
    }
   ],
   "source": [
    "n_layers = simulated_data['params'].max_layer_num\n",
    "n_params = simulated_data['params'].num_params\n",
    "\n",
    "print(f'Number of layers: {n_layers},  Number of film parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the model to simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the neural network consists in the *batch of* reflectivity curves together with the prior bounds (minimum and maximum) for each film parameter. For experimental data, the prior bounds can be set according to the prior knowledge about the investigated thin film. In this example on simulated data, we use the prior bounds already sampled during the data generation process (i.e. meant for training the model) which ensures reasonable values for the prior bounds. \n",
    "\n",
    "In the `scaled_params` tensor the first 8 columns correspond to the *scaled* ground truth values of the film parameters, the next 8 columns to the *scaled* minimum bounds for the parameters and the last 8 to the *scaled* maximum bounds for the parameters. Thus, we select the last 16 columns as our input prior bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "scaled_bounds = simulated_data['scaled_params'][..., n_params:]\n",
    "\n",
    "print(scaled_bounds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the input to the neural network, we concatenate the the reflectiviy curves with the prior bounds along the last axis of the tensor (`dim=-1`). We should also make sure that the input is of the `float` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 144])\n"
     ]
    }
   ],
   "source": [
    "scaled_input = torch.cat([scaled_noisy_curves, scaled_bounds], dim=-1).float()\n",
    "\n",
    "print(scaled_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network can be accessed as the `model` subobject of the trainer. By providing the previously constructed scaled input (reflectivity curves + prior bounds) to the network, we obtain the predictions for the parameters, scaled with respect to the prior bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The neural network must be first set to evaluation mode, as this influences the functionality of some neural network components such as the batch normalization layers.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trainer.model.eval()\n",
    "    \n",
    "    scaled_predicted_params = trainer.model(scaled_input)\n",
    "    \n",
    "print(scaled_predicted_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to restore the scaled predicted parameters to their unscaled (physical) values. Since the predicted parameters are scaled with respect to the input prior bounds, these are also required for the rescaling. We can concatenate the `scaled_predicted_params` and `scaled_bounds` tensors along the last tensor axis and provide them as input to the `restore_params` method of the prior sampler object (which can be accessed as `trainer.loader.prior_sampler`), the output being an instance of the `ParametricParams` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametricParams(batch_size=64, max_layer_num=2, device=cuda:0)\n"
     ]
    }
   ],
   "source": [
    "restored_predictions = trainer.loader.prior_sampler.restore_params(torch.cat([scaled_predicted_params, scaled_bounds], dim=-1))\n",
    "print(restored_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The physical predictions can then be accessed using the corresponding attribute for each parameter type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted thicknesses: tensor([170.7433, 351.2183], device='cuda:0', dtype=torch.float64)\n",
      "Predicted roughnesses: tensor([25.3218, 16.7337, 13.3724], device='cuda:0', dtype=torch.float64)\n",
      "Predicted layers SLDs: tensor([-18.5816,  -1.5489,  12.5732], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pred_idx = 0\n",
    "\n",
    "print(f'Predicted thicknesses: {restored_predictions.thicknesses[pred_idx]}')\n",
    "print(f'Predicted roughnesses: {restored_predictions.roughnesses[pred_idx]}')\n",
    "print(f'Predicted layers SLDs: {restored_predictions.slds[pred_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on the predictions, we can easily simulate the corresponding reflectivity curves by using the `reflectivity` method of the previously obtained `ParametricParams` instance, which takes the momentum transfer tensor *q* as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_curves = restored_predictions.reflectivity(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the input reflectivity curves alongside the curves correspondin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec095b42a0a4f45883636303ff51d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.5e-10, 5)\n",
    "\n",
    "    ax.set_xlabel('q [$Å^{-1}$]', fontsize=24)\n",
    "    ax.set_ylabel('R(q)', fontsize=24)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    y_tick_locations = [10**(-2*i) for i in range(6)]\n",
    "    ax.yaxis.set_major_locator(plt.FixedLocator(y_tick_locations))\n",
    "        \n",
    "    ax.scatter(q[i].cpu().numpy(), unscaled_noisy_curves[i].cpu().numpy() + 1e-10, c='b', s=2, label='input sim. curve')\n",
    "    ax.plot(q[i].cpu().numpy(), predicted_curves[i].cpu().numpy() + 1e-10, c='r', lw=1, label='prediction')\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model to experimental curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- ![](example_refl_curves_exp_V2.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- ![](sketch_multilayer_0.svg) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
