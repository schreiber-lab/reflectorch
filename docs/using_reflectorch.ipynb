{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using a trained reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is importing the necessary methods from the reflectorch package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "from reflectorch import get_trainer_by_name\n",
    "\n",
    "torch.manual_seed(0); # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to import a trained reflectorch model, we first have to specify the name of the trained model we wish to load. This name should match the name of the YAML configuration file used for training that model. Here we load a model for a 2-layer box parameterization of the thin film SLD profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model_name = 'c1_trained'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we initialize an instance of the `PointEstimatorTrainer` class using the `get_trainer_by_name` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{warning}\n",
    "The `load_weights` argument must be set to `True` in order for the saved weights of the neural network to be loaded, otherwise the network weights are randomly initialized.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model c1_trained loaded. Number of parameters: 3.83 M\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer_by_name(config_name=trained_model_name, load_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a batch of simulated data using the `get_batch` method of the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "simulated_data = trainer.loader.get_batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a dictionary with 4 entries indexed by the following keys:\n",
    "\n",
    " 1. **params** - an instance of the `ParametricParams` class containing the original (unscaled) values of the generated parameters, the generated minimum prior bound for each parameter and the generated maximum prior bound for each parameter (see the [paper](https://doi.org/10.1107/S1600576724002115) for more details about the generation process)\n",
    " 2. **scaled_params** - a Pytorch Tensor containing the parameters, minimum bounds and maximum bounds, all scaled to the ML-friendly range [-1, 1]\n",
    " 3. **q_values** - a Pytorch Tensor containing the reciprocal space (q) positions of the points in the reflectivity curve, in units of Å<sup>-1</sup>\n",
    " 4. **scaled_noisy_curves** - a Pytorch Tensor containing the simulated reflectivity curves (including added noise) scaled to the ML-friendly range [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect some of the (scaled) simulated curves: \n",
    "\n",
    "(*interactive cursor not supported in current version of Jupyter Book*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1815a5e44bd4112b391e49c538a44b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = simulated_data['q_values']\n",
    "scaled_noisy_curves = simulated_data['scaled_noisy_curves']\n",
    "unscaled_noisy_curves = trainer.loader.curves_scaler.restore(scaled_noisy_curves)\n",
    "\n",
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlabel('q [$Å^{-1}$]', fontsize=24)\n",
    "    ax.set_ylabel('R$_{scaled}$ (q)', fontsize=24)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        \n",
    "    ax.scatter(q[i].cpu().numpy(), scaled_noisy_curves[i].cpu().numpy(), c='blue', s=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trained model corresponds to a 2 layer (*in addition to the substrate*) parameterization of the SLD profile, which corresponds to 8 predicted film parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 2,  Number of film parameters: 8\n"
     ]
    }
   ],
   "source": [
    "n_layers = simulated_data['params'].max_layer_num\n",
    "n_params = simulated_data['params'].num_params\n",
    "\n",
    "print(f'Number of layers: {n_layers},  Number of film parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the model to simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the neural network consists in the batch of reflectivity curves together with the prior bounds (minimum and maximum) for each film parameter. For experimental data, the prior bounds can be set according to the prior knowledge about the investigated thin film. In this example on simulated data, we use the prior bounds already sampled during the data generation process (i.e. meant for training the model) which ensures reasonable values for the prior bounds. \n",
    "\n",
    "In the `scaled_params` tensor the first 8 columns correspond to the *scaled* ground truth values of the film parameters, the next 8 columns to the *scaled* minimum bounds for the parameters and the last 8 to the *scaled* maximum bounds for the parameters. Thus, we select the last 16 columns as our input prior bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "scaled_bounds = simulated_data['scaled_params'][..., n_params:]\n",
    "\n",
    "print(scaled_bounds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the input to the neural network, we concatenate the the reflectiviy curves with the prior bounds along the last axis of the tensor (`dim=-1`). We should also make sure that the input is of the `float` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 144])\n"
     ]
    }
   ],
   "source": [
    "scaled_input = torch.cat([scaled_noisy_curves, scaled_bounds], dim=-1).float()\n",
    "\n",
    "print(scaled_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network can be accessed as the `model` attribute of the trainer. By providing the previously constructed scaled input (reflectivity curves + prior bounds) to the network, we obtain the predictions for the parameters, scaled with respect to the prior bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The neural network must be first set to evaluation mode, as this influences the functionality of some neural network components such as the batch normalization layers.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    trainer.model.eval()\n",
    "    \n",
    "    scaled_predicted_params = trainer.model(scaled_input)\n",
    "    \n",
    "print(scaled_predicted_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to restore the scaled predicted parameters to their unscaled (physical) values. Since the predicted parameters are scaled with respect to the input prior bounds, these are also required for the rescaling. We can concatenate the `scaled_predicted_params` and `scaled_bounds` tensors along the last tensor axis and provide them as input to the `restore_params` method of the prior sampler object (which can be accessed as `trainer.loader.prior_sampler`), the output being an instance of the `ParametricParams` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParametricParams(batch_size=64, max_layer_num=2, device=cuda:0)\n"
     ]
    }
   ],
   "source": [
    "restored_predictions = trainer.loader.prior_sampler.restore_params(torch.cat([scaled_predicted_params, scaled_bounds], dim=-1))\n",
    "print(restored_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The physical predictions can then be accessed using the corresponding attribute for each parameter type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted thicknesses: tensor([185.6108, 392.6086], device='cuda:0', dtype=torch.float64)\n",
      "Predicted roughnesses: tensor([26.7255, 16.5625, 18.7021], device='cuda:0', dtype=torch.float64)\n",
      "Predicted layers SLDs: tensor([-18.5904,  -1.2606,  12.4019], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pred_idx = 0\n",
    "\n",
    "print(f'Predicted thicknesses: {restored_predictions.thicknesses[pred_idx]}')\n",
    "print(f'Predicted roughnesses: {restored_predictions.roughnesses[pred_idx]}')\n",
    "print(f'Predicted layers SLDs: {restored_predictions.slds[pred_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Based on the predictions, we can easily simulate the corresponding reflectivity curves by using the `reflectivity` method of the previously obtained `ParametricParams` object, which takes the q values as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_curves = restored_predictions.reflectivity(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the input reflectivity curves alongside the curves corresponding to the neural network prediction. Additionally, we can print the prediction for each parameter alongside its ground truth value and its prior bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b250f6c7e1974448a45a880361fd8bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from reflectorch import get_param_labels, get_density_profiles\n",
    "\n",
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(0.5e-10, 5)\n",
    "\n",
    "    ax[0].set_xlabel('q [$Å^{-1}$]', fontsize=20)\n",
    "    ax[0].set_ylabel('R(q)', fontsize=20)\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[0].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    y_tick_locations = [10**(-2*i) for i in range(6)]\n",
    "    ax[0].yaxis.set_major_locator(plt.FixedLocator(y_tick_locations))\n",
    "        \n",
    "    ax[0].plot(q[i].cpu().numpy(), predicted_curves[i].cpu().numpy() + 1e-10, c='r', lw=1, label='prediction')\n",
    "    ax[0].scatter(q[i].cpu().numpy(), unscaled_noisy_curves[i].cpu().numpy() + 1e-10, c='b', s=2, label='input sim. curve')\n",
    "\n",
    "    ax[0].legend(loc='upper right', fontsize=14)\n",
    "\n",
    "    z_axis = torch.linspace(-200, 1000, 1000, device='cuda')\n",
    "    _, sld_profile_gt, _ = get_density_profiles(\n",
    "         simulated_data['params'].thicknesses, \n",
    "         simulated_data['params'].roughnesses,\n",
    "         simulated_data['params'].slds,\n",
    "         z_axis)\n",
    "    \n",
    "    _, sld_profile_pred, _ = get_density_profiles(\n",
    "         restored_predictions.thicknesses, \n",
    "         restored_predictions.roughnesses,\n",
    "         restored_predictions.slds,\n",
    "         z_axis)\n",
    "    \n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_pred[i].cpu().numpy(), c='r', label='prediction')\n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_gt[i].cpu().numpy(), c='b', label='ground truth')\n",
    "\n",
    "    ax[1].set_xlabel('z [$Å$]', fontsize=20)\n",
    "    ax[1].set_ylabel('SLD [$10^{-6} Å^{-2}$]', fontsize=20)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[1].tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    for l, t, p, min_b, max_b in zip(\n",
    "          get_param_labels(2),\n",
    "          simulated_data['params'].parameters[i], \n",
    "          restored_predictions.parameters[i], \n",
    "          restored_predictions.min_bounds[i], \n",
    "          restored_predictions.max_bounds[i]\n",
    "          ):\n",
    "         print(f'{l.ljust(14)} --> True: {t:.2f} Predicted: {p:.2f}  Input prior bounds: ({min_b:.2f}, {max_b:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfa6b17e4ac45b9a59d206baaf9e4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, description='i', max=63), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=8):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(0.5e-10, 5)\n",
    "\n",
    "    ax[0].set_xlabel('q [$Å^{-1}$]', fontsize=20)\n",
    "    ax[0].set_ylabel('R(q)', fontsize=20)\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[0].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    y_tick_locations = [10**(-2*i) for i in range(6)]\n",
    "    ax[0].yaxis.set_major_locator(plt.FixedLocator(y_tick_locations))\n",
    "        \n",
    "    ax[0].plot(q[i].cpu().numpy(), predicted_curves[i].cpu().numpy() + 1e-10, c='r', lw=1, label='prediction')\n",
    "    ax[0].scatter(q[i].cpu().numpy(), unscaled_noisy_curves[i].cpu().numpy() + 1e-10, c='b', s=2, label='input sim. curve')\n",
    "\n",
    "    ax[0].legend(loc='upper right', fontsize=14)\n",
    "\n",
    "    z_axis = torch.linspace(-200, 1000, 1000, device='cuda')\n",
    "    _, sld_profile_gt, _ = get_density_profiles(\n",
    "         simulated_data['params'].thicknesses, \n",
    "         simulated_data['params'].roughnesses,\n",
    "         simulated_data['params'].slds,\n",
    "         z_axis)\n",
    "    \n",
    "    _, sld_profile_pred, _ = get_density_profiles(\n",
    "         restored_predictions.thicknesses, \n",
    "         restored_predictions.roughnesses,\n",
    "         restored_predictions.slds,\n",
    "         z_axis)\n",
    "    \n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_pred[i].cpu().numpy(), c='r', label='prediction')\n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_gt[i].cpu().numpy(), c='b', label='ground truth')\n",
    "\n",
    "    ax[1].set_xlabel('z [$Å$]', fontsize=20)\n",
    "    ax[1].set_ylabel('SLD [$10^{-6} Å^{-2}$]', fontsize=20)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[1].tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    for l, t, p, min_b, max_b in zip(\n",
    "          get_param_labels(2),\n",
    "          simulated_data['params'].parameters[i], \n",
    "          restored_predictions.parameters[i], \n",
    "          restored_predictions.min_bounds[i], \n",
    "          restored_predictions.max_bounds[i]\n",
    "          ):\n",
    "         print(f'{l.ljust(14)} --> True: {t:.2f} Predicted: {p:.2f}  Input prior bounds: ({min_b:.2f}, {max_b:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9594761c973c4fd094560abd6e8f3cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=13, description='i', max=63), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=13):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(0.5e-10, 5)\n",
    "\n",
    "    ax[0].set_xlabel('q [$Å^{-1}$]', fontsize=20)\n",
    "    ax[0].set_ylabel('R(q)', fontsize=20)\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[0].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    y_tick_locations = [10**(-2*i) for i in range(6)]\n",
    "    ax[0].yaxis.set_major_locator(plt.FixedLocator(y_tick_locations))\n",
    "        \n",
    "    ax[0].plot(q[i].cpu().numpy(), predicted_curves[i].cpu().numpy() + 1e-10, c='r', lw=1, label='prediction')\n",
    "    ax[0].scatter(q[i].cpu().numpy(), unscaled_noisy_curves[i].cpu().numpy() + 1e-10, c='b', s=2, label='input sim. curve')\n",
    "\n",
    "    ax[0].legend(loc='upper right', fontsize=14)\n",
    "\n",
    "    z_axis = torch.linspace(-200, 1000, 1000, device='cuda')\n",
    "    _, sld_profile_gt, _ = get_density_profiles(\n",
    "         simulated_data['params'].thicknesses, \n",
    "         simulated_data['params'].roughnesses,\n",
    "         simulated_data['params'].slds,\n",
    "         z_axis)\n",
    "    \n",
    "    _, sld_profile_pred, _ = get_density_profiles(\n",
    "         restored_predictions.thicknesses, \n",
    "         restored_predictions.roughnesses,\n",
    "         restored_predictions.slds,\n",
    "         z_axis)\n",
    "    \n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_pred[i].cpu().numpy(), c='r', label='prediction')\n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_gt[i].cpu().numpy(), c='b', label='ground truth')\n",
    "\n",
    "    ax[1].set_xlabel('z [$Å$]', fontsize=20)\n",
    "    ax[1].set_ylabel('SLD [$10^{-6} Å^{-2}$]', fontsize=20)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[1].tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    for l, t, p, min_b, max_b in zip(\n",
    "          get_param_labels(2),\n",
    "          simulated_data['params'].parameters[i], \n",
    "          restored_predictions.parameters[i], \n",
    "          restored_predictions.min_bounds[i], \n",
    "          restored_predictions.max_bounds[i]\n",
    "          ):\n",
    "         print(f'{l.ljust(14)} --> True: {t:.2f} Predicted: {p:.2f}  Input prior bounds: ({min_b:.2f}, {max_b:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified use of a trained reflectorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact\n",
    "from reflectorch import EasyInferenceModel\n",
    "\n",
    "torch.manual_seed(0); # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `EasyInferenceModel` class simplifies the inference step for single input reflectivity curves. We initialize an instance using the configuration file of a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model c1_trained\n",
      "Model c1_trained loaded. Number of parameters: 3.83 M\n",
      "Model c1_trained is loaded.\n"
     ]
    }
   ],
   "source": [
    "inference_model = EasyInferenceModel(config_name='c1_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the prior bounds for the parameters as a list of tuples `(min_prior_bound, max_prior_bound)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_bounds = [(10., 500.), (10., 500.), #thicknesses (top to bottom)\n",
    "                (0., 60.), (0., 60.), (0., 60.), #roughnesses (top to bottom)\n",
    "                (-18., -16.), (-3., 0.), (9., 13.)] #slds (top to bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reflectivity curve and its corresponding q values should be Numpy array of Pytorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "scroll-input"
    ]
   },
   "outputs": [],
   "source": [
    "reflectivity_curve = np.array([\n",
    "        1.1851e+00, 1.3166e+00, 1.2792e+00, 1.1838e+00, 1.1931e+00, 3.9305e-01,\n",
    "        2.3147e-01, 1.5170e-01, 1.0417e-01, 7.7329e-02, 7.1802e-02, 7.9045e-02,\n",
    "        7.3709e-02, 9.2383e-02, 7.2035e-02, 8.3879e-02, 6.7362e-02, 3.8931e-02,\n",
    "        3.2731e-02, 1.7164e-02, 6.0003e-03, 6.0304e-04, 4.4626e-04, 4.1207e-03,\n",
    "        8.3723e-03, 1.5344e-02, 2.0189e-02, 2.3262e-02, 1.6822e-02, 2.0629e-02,\n",
    "        1.6630e-02, 1.3288e-02, 8.9167e-03, 4.3387e-03, 2.2806e-03, 5.7447e-04,\n",
    "        5.2052e-05, 3.4333e-04, 1.1657e-03, 1.3885e-03, 2.4396e-03, 2.6531e-03,\n",
    "        2.6255e-03, 3.2867e-03, 2.2043e-03, 1.8492e-03, 1.2300e-03, 1.0895e-03,\n",
    "        7.5618e-04, 5.9881e-04, 4.6538e-04, 3.8349e-04, 1.9684e-04, 1.1074e-04,\n",
    "        7.1625e-05, 4.6080e-05, 8.6055e-05, 1.4261e-04, 2.6008e-04, 3.9065e-04,\n",
    "        4.6900e-04, 4.9829e-04, 4.5922e-04, 4.7470e-04, 4.3097e-04, 3.1221e-04,\n",
    "        2.2763e-04, 1.7086e-04, 5.9867e-05, 1.5550e-05, 1.8952e-07, 9.6534e-06,\n",
    "        3.6830e-05, 6.7740e-05, 9.9643e-05, 1.2925e-04, 1.3112e-04, 1.2955e-04,\n",
    "        1.1382e-04, 9.9504e-05, 7.7012e-05, 5.0792e-05, 3.9126e-05, 1.4859e-05,\n",
    "        9.1510e-06, 3.9761e-06, 1.3064e-06, 2.2066e-06, 4.5884e-06, 8.6499e-06,\n",
    "        1.3575e-05, 1.2752e-05, 1.9014e-05, 1.9985e-05, 2.0350e-05, 2.0645e-05,\n",
    "        1.6298e-05, 1.2674e-05, 1.0688e-05, 8.1643e-06, 3.9810e-06, 2.2977e-06,\n",
    "        5.9902e-07, 1.4382e-07, 4.5002e-07, 1.2234e-06, 2.3017e-06, 3.2775e-06,\n",
    "        3.6404e-06, 4.4081e-06, 4.1741e-06, 3.3690e-06, 3.3674e-06, 2.4155e-06,\n",
    "        1.9592e-06, 1.4078e-06, 9.6771e-07, 3.9546e-07, 1.8652e-07, 5.3041e-08,\n",
    "        1.0580e-07, 2.0595e-07, 3.3874e-07, 5.7800e-07, 7.7420e-07, 5.6977e-07,\n",
    "        6.6871e-07, 6.9172e-07\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "scroll-input"
    ]
   },
   "outputs": [],
   "source": [
    "q_values = np.array([\n",
    "        0.0201, 0.0211, 0.0222, 0.0232, 0.0242, 0.0252, 0.0262, 0.0273, 0.0283,\n",
    "        0.0293, 0.0303, 0.0314, 0.0324, 0.0334, 0.0344, 0.0355, 0.0365, 0.0375,\n",
    "        0.0385, 0.0396, 0.0406, 0.0416, 0.0426, 0.0436, 0.0447, 0.0457, 0.0467,\n",
    "        0.0477, 0.0488, 0.0498, 0.0508, 0.0518, 0.0529, 0.0539, 0.0549, 0.0559,\n",
    "        0.0570, 0.0580, 0.0590, 0.0600, 0.0611, 0.0621, 0.0631, 0.0641, 0.0651,\n",
    "        0.0662, 0.0672, 0.0682, 0.0692, 0.0703, 0.0713, 0.0723, 0.0733, 0.0744,\n",
    "        0.0754, 0.0764, 0.0774, 0.0785, 0.0795, 0.0805, 0.0815, 0.0825, 0.0836,\n",
    "        0.0846, 0.0856, 0.0866, 0.0877, 0.0887, 0.0897, 0.0907, 0.0918, 0.0928,\n",
    "        0.0938, 0.0948, 0.0959, 0.0969, 0.0979, 0.0989, 0.0999, 0.1010, 0.1020,\n",
    "        0.1030, 0.1040, 0.1051, 0.1061, 0.1071, 0.1081, 0.1092, 0.1102, 0.1112,\n",
    "        0.1122, 0.1133, 0.1143, 0.1153, 0.1163, 0.1174, 0.1184, 0.1194, 0.1204,\n",
    "        0.1214, 0.1225, 0.1235, 0.1245, 0.1255, 0.1266, 0.1276, 0.1286, 0.1296,\n",
    "        0.1307, 0.1317, 0.1327, 0.1337, 0.1348, 0.1358, 0.1368, 0.1378, 0.1388,\n",
    "        0.1399, 0.1409, 0.1419, 0.1429, 0.1440, 0.1450, 0.1460, 0.1470, 0.1481,\n",
    "        0.1491, 0.1501\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can invoke the `predict` method of the inference model to obtain the neural network predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.91821001 311.47147564  21.61200643  15.18360972  22.33419299\n",
      " -17.03783431  -1.59246207  11.33759486]\n"
     ]
    }
   ],
   "source": [
    "predicted_params = inference_model.predict(reflectivity_curve, q_values, prior_bounds)\n",
    "print(predicted_params.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By invoking the method `predict_using_widget`, one can make use of an interactive Jupyter notebook widget for selecting the minimum and maximum prior bound for each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter ranges: {'thicknesses': [0.0, 500.0], 'roughnesses': [0.0, 60.0], 'slds': [-25.0, 25.0]}\n",
      "Allowed widths of the prior bound intervals (max-min): {'thicknesses': [0.01, 500.0], 'roughnesses': [0.01, 60.0], 'slds': [0.01, 4.0]}\n",
      "Please fill in the values of the minimum and maximum prior bound for each parameter and press the button!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f706bcda64c470795bd36a7565388fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Thickness L2'), FloatText(value=0.0, description='min', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4453b1a638481bb1f233b0e820e197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Make prediction', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_params = inference_model.predict_using_widget(reflectivity_curve, q_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
