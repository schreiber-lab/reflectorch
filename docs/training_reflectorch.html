
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>5. Training a reflectorch model &#8212; Reflectorch Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'training_reflectorch';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Advanced functionality" href="advanced_functionality.html" />
    <link rel="prev" title="4. Neutron reflectometry use" href="using_reflectorch_neutron.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/reflectorch_logo.png" class="logo__image only-light" alt="Reflectorch Documentation - Home"/>
    <script>document.write(`<img src="_static/reflectorch_logo.png" class="logo__image only-dark" alt="Reflectorch Documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Reflectorch
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="simulations.html">2. Simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_reflectorch.html">3. Using a trained reflectorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_reflectorch_neutron.html">4. Neutron reflectometry use</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Training a reflectorch model</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_functionality.html">6. Advanced functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">7. API Reference</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>



<a href="https://github.com/schreiber-lab/reflectorch" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/training_reflectorch.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Training a reflectorch model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-training-loop">5.1. The training loop</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-trainer">5.1.1. Loading the trainer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-callbacks">5.1.2. Defining callbacks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-training">5.1.3. Run the training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-from-the-terminal">5.1.4. Training from the terminal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#customizing-the-yaml-configuration-for-training">5.2. Customizing the YAML configuration for training</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="training-a-reflectorch-model">
<h1><span class="section-number">5. </span>Training a reflectorch model<a class="headerlink" href="#training-a-reflectorch-model" title="Link to this heading">#</a></h1>
<p>First, we import the necessary methods from the <code class="docutils literal notranslate"><span class="pre">reflectorch</span></code> package, as well as other basic Python packages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">reflectorch</span> <span class="kn">import</span> <span class="n">SAVED_MODELS_DIR</span><span class="p">,</span> <span class="n">SaveBestModel</span><span class="p">,</span> <span class="n">StepLR</span><span class="p">,</span> <span class="n">get_trainer_by_name</span><span class="p">,</span> <span class="n">get_callbacks_by_name</span>
<span class="kn">from</span> <span class="nn">reflectorch.extensions.jupyter</span> <span class="kn">import</span> <span class="n">JPlotLoss</span>
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition tip">
<p class="admonition-title">Tip</p>
<p>Alternatively, we can import everything from reflectorch with
<code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">reflectorch</span> <span class="pre">import</span> <span class="pre">*</span></code></p>
</div>
<section id="the-training-loop">
<h2><span class="section-number">5.1. </span>The training loop<a class="headerlink" href="#the-training-loop" title="Link to this heading">#</a></h2>
<section id="loading-the-trainer">
<h3><span class="section-number">5.1.1. </span>Loading the trainer<a class="headerlink" href="#loading-the-trainer" title="Link to this heading">#</a></h3>
<p>For training a model we use the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class, which contains all the components necessary for the training process such as the data generator, the neural network and the optimizer.</p>
<p>We can initialize the trainer according to the specifications defined in a YAML configuration file using the <code class="docutils literal notranslate"><span class="pre">get_trainer_by_name</span></code> method which takes as input the name of the configuration file. If the package was installed in editable model, the configuration files are read from the <code class="docutils literal notranslate"><span class="pre">configs</span></code> directory located inside the repository, otherwise the path to the directory containing the configuration file should also be specified using the <code class="docutils literal notranslate"><span class="pre">config_dir</span></code> argument. The <code class="docutils literal notranslate"><span class="pre">load_weights</span></code> argument should be set to <code class="docutils literal notranslate"><span class="pre">False</span></code> since we want the neural network weights to be randomly initialized for a fresh training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config_name</span> <span class="o">=</span> <span class="s1">&#39;a_base_point_xray_conv_standard&#39;</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">get_trainer_by_name</span><span class="p">(</span><span class="n">config_name</span><span class="p">,</span> <span class="n">load_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model a_base_point_xray_conv_standard loaded. Number of parameters: 5.02 M
</pre></div>
</div>
</div>
</div>
<p>The trainer contains several important attributes we can inspect:</p>
<ol class="arabic simple">
<li><p>The Pytorch optimizer. We can observe that the optimizer specified in the configuration is <code class="docutils literal notranslate"><span class="pre">AdamW</span></code>:</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">optim</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>AdamW (
Parameter Group 0
    amsgrad: False
    betas: [0.9, 0.999]
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.0005
)
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The learning rate can be easily changed using <code class="docutils literal notranslate"><span class="pre">trainer.set_lr(new_lr)</span></code></p>
</div>
<ol class="arabic simple" start="2">
<li><p>The batch size</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">batch_size</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4096
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="3">
<li><p>The Pytorch neural network module. We can see that the network is an instance of the class <code class="docutils literal notranslate"><span class="pre">NetworkWithPriors</span></code>. This architecture consists of a multilayer perceptron (MLP) with residual connections, batch normalization layers and GELU activations (<code class="docutils literal notranslate"><span class="pre">trainer.model.mlp</span></code>). An embedding network, here a 1D CNN (<code class="docutils literal notranslate"><span class="pre">trainer.model.embedding_net</span></code>), produces a latent embedding of the input batch of reflectivity curves which is concatenated with the prior bounds for the thin film parameters.</p></li>
</ol>
<div class="cell tag_scroll-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NetworkWithPriors(
  (embedding_net): ConvEncoder(
    (core): Sequential(
      (0): Sequential(
        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))
        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU(approximate=&#39;none&#39;)
      )
      (1): Sequential(
        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU(approximate=&#39;none&#39;)
      )
      (2): Sequential(
        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU(approximate=&#39;none&#39;)
      )
      (3): Sequential(
        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU(approximate=&#39;none&#39;)
      )
      (4): Sequential(
        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU(approximate=&#39;none&#39;)
      )
    )
    (avpool): AdaptiveAvgPool1d(output_size=1)
    (fc): Linear(in_features=512, out_features=128, bias=True)
  )
  (mlp): ResidualMLP(
    (first_layer): Linear(in_features=128, out_features=512, bias=True)
    (blocks): ModuleList(
      (0-7): 8 x ResidualBlock(
        (activation): GELU(approximate=&#39;none&#39;)
        (batch_norm_layers): ModuleList(
          (0-1): 2 x BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        )
        (condition_layer): Linear(in_features=16, out_features=1024, bias=True)
        (linear_layers): ModuleList(
          (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)
        )
      )
    )
    (last_layer): Linear(in_features=512, out_features=8, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-callbacks">
<h3><span class="section-number">5.1.2. </span>Defining callbacks<a class="headerlink" href="#defining-callbacks" title="Link to this heading">#</a></h3>
<p>We can control the training process using callback objects, such as:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">JPlotLoss</span></code> - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the <code class="docutils literal notranslate"><span class="pre">frequency</span></code> argument setting the refresh rate of the interactive widget</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p><code class="docutils literal notranslate"><span class="pre">StepLR</span></code> - implements a learning rate scheduler which decreases the learning rate in steps (after a number of iterations defined by <code class="docutils literal notranslate"><span class="pre">step_size</span></code> the learning rate is multiplied by the factor <code class="docutils literal notranslate"><span class="pre">gamma</span></code>). Other types of learning rate schedulers can alternatively be used, such as <code class="docutils literal notranslate"><span class="pre">CosineAnnealingWithWarmup</span></code>, <code class="docutils literal notranslate"><span class="pre">LogCyclicLR</span></code>, <code class="docutils literal notranslate"><span class="pre">OneCycleLR</span></code> or <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p><code class="docutils literal notranslate"><span class="pre">SaveBestModel</span></code> - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the <code class="docutils literal notranslate"><span class="pre">freq</span></code> argument, the weights of the neural network are saved at the specified <code class="docutils literal notranslate"><span class="pre">path</span></code> if the current average loss (computed over the last <code class="docutils literal notranslate"><span class="pre">average</span></code> iterations) is lower than the loss for the previous save. The history of the losses and learning rate values is also saved.</p></li>
</ol>
<p>When the package is installed in editable mode, the default save path is relative to the repository directory (defined by the global variable <code class="docutils literal notranslate"><span class="pre">SAVED_MODELS_DIR</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model_name</span> <span class="o">=</span> <span class="s1">&#39;model_&#39;</span> <span class="o">+</span> <span class="n">config_name</span> <span class="o">+</span> <span class="s1">&#39;.pt&#39;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">SAVED_MODELS_DIR</span> <span class="o">/</span> <span class="n">save_model_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We group the callback objects together in a touple:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">callbacks</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">JPlotLoss</span><span class="p">(</span><span class="n">frequency</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> 
    <span class="n">StepLR</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">last_epoch</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> 
    <span class="n">SaveBestModel</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The callbacks can also be initialized directly from the configuration file:
<code class="docutils literal notranslate"><span class="pre">callbacks</span> <span class="pre">=</span> <span class="pre">get_callbacks_by_name(config_name)</span></code></p>
</div>
</section>
<section id="run-the-training">
<h3><span class="section-number">5.1.3. </span>Run the training<a class="headerlink" href="#run-the-training" title="Link to this heading">#</a></h3>
<p>The training process is initiated by calling the <code class="docutils literal notranslate"><span class="pre">train</span></code> method of the trainer. This method accepts as arguments the previously defined tuple of callbacks, as well as the number of iterations (batches). Notably, a new batch of data is generated at each iteration, the training taking place in a “one-epoch regime”.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_batches</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
<p>After training, the history of the losses and learning rates can be accessed via <code class="docutils literal notranslate"><span class="pre">trainer.losses</span></code> and <code class="docutils literal notranslate"><span class="pre">trainer.lrs</span></code>. We can also find them together with the model state_dict in the saved dictionary:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;model&#39;, &#39;lrs&#39;, &#39;losses&#39;, &#39;prev_save&#39;, &#39;batch_num&#39;, &#39;best_loss&#39;])
</pre></div>
</div>
</div>
</div>
<div class="dropdown admonition tip">
<p class="admonition-title">Tip</p>
<p>The saved weights can be loaded into a compatible neural network (<code class="docutils literal notranslate"><span class="pre">net</span></code>) as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">saved_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
<span class="n">model_state_dict</span> <span class="o">=</span> <span class="n">saved_dict</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
<span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The model state dictionaries of all the saved ‘.pt’ files in a directory can be further converted to the ‘.safetensors’ format for exporting to Huggingface using the <code class="docutils literal notranslate"><span class="pre">convert_pt_to_safetensors</span></code> method.</p>
</section>
<section id="training-from-the-terminal">
<h3><span class="section-number">5.1.4. </span>Training from the terminal<a class="headerlink" href="#training-from-the-terminal" title="Link to this heading">#</a></h3>
<p>Above we described the workflow for training a model in a Jupyter Notebook, where we loaded the trainer from the configuration file but defined the callbacks manually. Alternatively, one can train a model from the terminal (in this case the callbacks defined in the configuration file are used):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>reflectorch.train<span class="w"> </span>config_name
</pre></div>
</div>
</section>
</section>
<section id="customizing-the-yaml-configuration-for-training">
<h2><span class="section-number">5.2. </span>Customizing the YAML configuration for training<a class="headerlink" href="#customizing-the-yaml-configuration-for-training" title="Link to this heading">#</a></h2>
<p>In the following we show how the YAML configuration file can be customized.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
Sample YAML configuration<div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">general</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">a_base_point_xray_conv_standard</span>
<span class="w">  </span><span class="nt">root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span>
<span class="nt">dset</span><span class="p">:</span>
<span class="w">  </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ReflectivityDataLoader</span>
<span class="w">  </span><span class="nt">prior_sampler</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SubpriorParametricSampler</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">param_ranges</span><span class="p">:</span>
<span class="w">        </span><span class="nt">thicknesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">500.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">roughnesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">60.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">slds</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">50.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">bound_width_ranges</span><span class="p">:</span>
<span class="w">        </span><span class="nt">thicknesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">500.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">roughnesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">60.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">slds</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">5.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">model_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standard_model</span>
<span class="w">      </span><span class="nt">max_num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">constrained_roughness</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">max_thickness_share</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="w">      </span><span class="nt">logdist</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">scale_params_by_ranges</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">scaled_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">-1.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
<span class="w">      </span>
<span class="w">  </span><span class="nt">q_generator</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ConstantQ</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">q</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.02</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.15</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
<span class="w">      </span>
<span class="w">  </span><span class="nt">intensity_noise</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">GaussianExpIntensityNoise</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">relative_errors</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.01</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.3</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">consistent_rel_err</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">apply_shift</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">shift_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">-0.3</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.3</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">add_to_context</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">  </span><span class="nt">curves_scaler</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LogAffineCurvesScaler</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">      </span><span class="nt">bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">      </span><span class="nt">eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-10</span>

<span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">network</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">NetworkWithPriors</span>
<span class="w">    </span><span class="nt">pretrained_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">embedding_net_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;conv&#39;</span>
<span class="w">      </span><span class="nt">embedding_net_kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">in_channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">        </span><span class="nt">hidden_channels</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">32</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">64</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">256</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">512</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">dim_embedding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">        </span><span class="nt">dim_avpool</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">        </span><span class="nt">use_batch_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">        </span><span class="nt">use_se</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">        </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;gelu&#39;</span>
<span class="w">      </span><span class="nt">pretrained_embedding_net</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">      </span><span class="nt">dim_out</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">      </span><span class="nt">dim_conditioning_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">      </span><span class="nt">layer_width</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">      </span><span class="nt">num_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">      </span><span class="nt">repeats_per_block</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">residual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">use_batch_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">use_layer_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">mlp_activation</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;gelu&#39;</span>
<span class="w">      </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"> </span>
<span class="w">      </span><span class="nt">conditioning</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;film&#39;</span>
<span class="w">      </span><span class="nt">concat_condition_first_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">       </span>
<span class="nt">training</span><span class="p">:</span>
<span class="w">  </span><span class="nt">trainer_cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PointEstimatorTrainer</span>
<span class="w">  </span><span class="nt">num_iterations</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
<span class="w">  </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-3</span>
<span class="w">  </span><span class="nt">grad_accumulation_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">clip_grad_norm_max</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">update_tqdm_freq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">AdamW</span>
<span class="w">  </span><span class="nt">trainer_kwargs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">train_with_q_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">condition_on_q_resolutions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">rescale_loss_interval_width</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">use_l1_loss</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">optim_kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">betas</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.9</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.999</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0005</span>
<span class="w">  </span><span class="nt">callbacks</span><span class="p">:</span>
<span class="w">    </span><span class="nt">save_best_model</span><span class="p">:</span>
<span class="w">      </span><span class="nt">enable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">freq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span>
<span class="w">    </span><span class="nt">lr_scheduler</span><span class="p">:</span>
<span class="w">      </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CosineAnnealingWithWarmup</span>
<span class="w">      </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">min_lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-6</span>
<span class="w">        </span><span class="nt">warmup_iters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span>
<span class="w">        </span><span class="nt">total_iters</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span>

<span class="w">  </span><span class="nt">logger</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TensorBoardLogger</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">log_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;tensorboard_runs/test_1&quot;</span>
</pre></div>
</div>
</div>
</details><p>The <code class="docutils literal notranslate"><span class="pre">general</span></code> key, contains the following subkeys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> - name used for saving the model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">root</span></code> - path to the root directory, defaults to the package directory</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">general</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">a_base_point_xray_conv_standard</span>
<span class="w">  </span><span class="nt">root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">dset</span></code> key defines the settings pertaining to the data generation (i.e. the SLD profile parameterization, the ranges of the thin film parameters, the q values, the noise added to the reflectivity curves and the scaling of the reflectivity curves). It has the following subkeys:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cls</span></code> (<em>optional</em>) - the class of the data loader. If not provided, the default class <code class="docutils literal notranslate"><span class="pre">ReflectivityDataLoader</span></code> is used.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p><code class="docutils literal notranslate"><span class="pre">prior_sampler</span></code> - responsible for defining the type of SLD parameterization, the ranges from which the thin film parameters are sampled and the ranges from which the widths of the prior bounds are sampled. The <code class="docutils literal notranslate"><span class="pre">SubpriorParametricSampler</span></code> class first samples a center (<strong>C</strong>) from the parameter ranges and a width (<strong>W</strong>) from the bound width ranges. This defines a subinterval delimited by the minimum prior bound <strong>B_min</strong> = <strong>C</strong> - <strong>W</strong>/2 and the maximum prior bound <strong>B_max</strong> = <strong>C</strong> + <strong>W</strong>/2. Then, the values of the parameters (to be used for simulating the reflectivity curves and as ground truth) are uniformly sampled within the interval [<strong>B_min</strong>, <strong>B_max</strong>]. It has the following keyword arguments:</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_name</span></code> - name associated with the type of SLD parameterization. Here, <code class="docutils literal notranslate"><span class="pre">standard_model</span></code> represents the standard box model parameterization of the SLD with the parameters thickness, roughness and real layer SLD.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_num_layers</span></code> - the number of layers in the thin film (in addition to the substrate)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">param_ranges</span></code> - the ranges from which the values of each type of thin film parameter are uniformly sampled (for the standard model <code class="docutils literal notranslate"><span class="pre">thicknesses</span></code>, <code class="docutils literal notranslate"><span class="pre">roughnesses</span></code> and <code class="docutils literal notranslate"><span class="pre">slds</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bound_width_ranges</span></code> - the ranges from which the prior bound widths of each type of thin film parameter are uniformly sampled. If the argument <code class="docutils literal notranslate"><span class="pre">logdist</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the prior bound widths are sampled uniformly on a logarithmic scale instead, biasing the training towards smaller prior bound widths.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constrained_roughness</span></code> - if <code class="docutils literal notranslate"><span class="pre">true</span></code> the sampling of the roughness parameters is constrained such that the roughness of an interface between two layers does not exceed a fraction (defined by the argument <code class="docutils literal notranslate"><span class="pre">max_thickness_share</span></code>) of the thickness of either one of those layers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_total_thickness</span></code> (optional) - if provided, the sampling is performed such that the sum of the sampled layer thicknesses does not exceed this value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scale_params_by_ranges</span></code> - if <code class="docutils literal notranslate"><span class="pre">true</span></code> the parameters are scaled with respect to their ranges, otherwise they are scaled with respect to their subprior bound interval. The default is <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scaled_range</span></code> - the ML-friendly range to which the parameters (and prior bounds) are scaled to, the default is [-1, 1]</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code> - default is <code class="docutils literal notranslate"><span class="pre">'cuda'</span></code> for GPU use, can be changed to <code class="docutils literal notranslate"><span class="pre">'cpu'</span></code> for CPU use</p></li>
</ul>
<figure class="align-center" id="figure-reflectometry-network">
<a class="reference internal image-reference" href="_images/FigureReflectometryNetwork.png"><img alt="_images/FigureReflectometryNetwork.png" src="_images/FigureReflectometryNetwork.png" style="width: 582.0px; height: 244.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5.1 </span><span class="caption-text">(a) Parameter sampling process (b) Neural network architecture</span><a class="headerlink" href="#figure-reflectometry-network" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dset</span><span class="p">:</span>
<span class="w">  </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ReflectivityDataLoader</span>
<span class="w">  </span><span class="nt">prior_sampler</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">SubpriorParametricSampler</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">param_ranges</span><span class="p">:</span>
<span class="w">        </span><span class="nt">thicknesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">500.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">roughnesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">60.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">slds</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">50.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">bound_width_ranges</span><span class="p">:</span>
<span class="w">        </span><span class="nt">thicknesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">500.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">roughnesses</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">60.</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">slds</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-2</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">5.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">model_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standard_model</span>
<span class="w">      </span><span class="nt">max_num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">constrained_roughness</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">max_thickness_share</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="w">      </span><span class="nt">logdist</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">scale_params_by_ranges</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">scaled_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">-1.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p><code class="docutils literal notranslate"><span class="pre">q_generator</span></code> - responsible for generating the transfer vector (q) values at which the reflectivity is to be simulated. We must first specifiy its class. The <code class="docutils literal notranslate"><span class="pre">ConstantQ</span></code> class generates a fixed discretization for all the reflectivity curves in the batch. Its <code class="docutils literal notranslate"><span class="pre">q</span></code> keyword argument is a tuple formatted as <em>[q_min, q_max, num_q_points]</em>, which defines the minimum q value, the maximum q value as well as the number of points (including the interval boundaries) to be equidistantly sampled. Other q generator classes are available such as <code class="docutils literal notranslate"><span class="pre">VariableQ</span></code> (equidistant grid with variable <em>q_min</em>, <em>q_max</em> and <em>num_q_points</em>, further described in the <em>Advanced functionality</em> section) and <code class="docutils literal notranslate"><span class="pre">ConstantAngle</span></code> which generates the grid of q values based on equidistantlly sampled scattering angles and the wavelength of the beam. The <code class="docutils literal notranslate"><span class="pre">device</span></code> argument can be changed to <code class="docutils literal notranslate"><span class="pre">'cpu'</span></code> for CPU use (default is <code class="docutils literal notranslate"><span class="pre">'cuda'</span></code> for GPU use).</p></li>
</ol>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dset</span><span class="p">:</span>
<span class="w">  </span><span class="nt">q_generator</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ConstantQ</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">q</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.02</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.15</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
<span class="w">      </span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p><code class="docutils literal notranslate"><span class="pre">q_noise</span></code> (<em>optional</em>) - responsible for adding noise to the generated q values, which emulates possible measurement errors due to sample misalignment. The <code class="docutils literal notranslate"><span class="pre">BasicQNoiseGenerator</span></code> class can add both systematic q shifts (the same change applied to all q points of a curve) and random noise (different changes applied to each q point of a curve) to the q values of the batch of curves, it has the following arguments:</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">shift_std</span></code> - the standard deviation of the normal distribution for sampling the systematic q shifts (one value sampled per curve in the batch)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">noise_std</span></code> - the standard deviation of the normal distribution for sampling the random q noise (one value sampled per point in the curve). The standard deviation is the same for all curves in the batch if provided as a float, or uniformly sampled from a range for each curve in the batch if provided as a tuple.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dset</span><span class="p">:</span>
<span class="w">  </span><span class="nt">q_noise</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BasicQNoiseGenerator</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">shift_std</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-3</span>
<span class="w">      </span><span class="nt">noise_std</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.0e-3</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<ol class="arabic" start="5">
<li><p><code class="docutils literal notranslate"><span class="pre">intensity_noise</span></code> - responsible for adding noise to the intensity values of the reflectivity curves.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">GaussianExpIntensityNoise</span></code> combines three types of noise:</p>
<ul class="simple">
<li><p>Gaussian noise: Applies Gaussian noise to account for count-based Poisson noise as well as other sources of error.</p></li>
<li><p>Shift noise: Applies a multiplicative scaling to the curves, equivalent to a vertical shift in logarithmic space.</p></li>
<li><p>Background noise: Adds a constant background to the curves.</p></li>
</ul>
<p>It has the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">relative_errors</span></code> - range of relative errors for Gaussian noise.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">consistent_rel_err</span></code> - if <code class="docutils literal notranslate"><span class="pre">true</span></code>, uses a consistent relative error for Gaussian noise across all points in a curve.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">apply_shift</span></code> - if <code class="docutils literal notranslate"><span class="pre">true</span></code>, applies shift noise to the curves.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shift_range</span></code> - range of shift factors for shift noise.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">apply_background</span></code> - if <code class="docutils literal notranslate"><span class="pre">true</span></code>, applies background noise to the curves.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">background_range</span></code> - range for background values.</p></li>
</ul>
</li>
</ol>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">intensity_noise</span><span class="p">:</span>
<span class="w">  </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">GaussianExpIntensityNoise</span>
<span class="w">  </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">relative_errors</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.01</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.3</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">consistent_rel_err</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">apply_shift</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">shift_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">-0.3</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.3</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">apply_background</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">background_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">1.0e-10</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">1.0e-4</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">add_to_context</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p><code class="docutils literal notranslate"><span class="pre">smearing</span></code> (<em>optional</em>) - responsible for adding resolution smearing to the curves (which can occur in neutron experiments due to uncertainties in incident angle  or wavelength). The intensity at a q point will be the average of the intensities of neighbouring q points, weighted by a gaussian profile. The arguments of the <code class="docutils literal notranslate"><span class="pre">Smearing</span></code> class are:</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sigma_range</span></code> - the range for sampling the resolutions</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constant_dq</span></code> - if <code class="docutils literal notranslate"><span class="pre">True</span></code> the smearing is constant (the resolution is given by the constant dq at each point in the curve, i.e. x-ray variant), otherwise the smearing is linear (the resolution is given by the constant dq/q at each point in the curve, i.e. neutron variant)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gauss_num</span></code> - the number of points used to define the Gaussian smearing kernel. A higher number increases precision at the cost of computational efficiency.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">share_smeared</span></code> - the share of curves in the batch for which the resolution smearing is applied</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dset</span><span class="p">:</span><span class="w">   </span>
<span class="w">  </span><span class="nt">smearing</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Smearing</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">sigma_range</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.01</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.08</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">constant_dq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">      </span><span class="nt">gauss_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">17</span>
<span class="w">      </span><span class="nt">share_smeared</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.8</span>
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li><p><code class="docutils literal notranslate"><span class="pre">curves_scaler</span></code> - responsible for scaling the reflectivity curves to a ML-friendly range. The <code class="docutils literal notranslate"><span class="pre">LogAffineCurvesScaler</span></code> class scales the reflectivity curves (R) accoring to the formula:</p></li>
</ol>
<p><span class="math notranslate nohighlight">\(R_{scaled} = log_{10}(R + eps) \times weight + bias\)</span></p>
<p>The argument <code class="docutils literal notranslate"><span class="pre">eps</span></code> sets the minimum intensity value of the reflectivity curves which is considered. The default values of 1.0e-10 for <code class="docutils literal notranslate"><span class="pre">eps</span></code>, 0.2 for <code class="docutils literal notranslate"><span class="pre">weight</span></code> and 1.0 for <code class="docutils literal notranslate"><span class="pre">bias</span></code> results in the interval [-1, 1] for the scaled reflectivity curves.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">dset</span><span class="p">:</span><span class="w">    </span>
<span class="w">  </span><span class="nt">curves_scaler</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LogAffineCurvesScaler</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">      </span><span class="nt">bias</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">      </span><span class="nt">eps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-10</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model</span></code> key defines the neural network architecture. Its <code class="docutils literal notranslate"><span class="pre">network</span></code> subkey contains the following subkeys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cls</span></code> - the class of the neural network</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pretrained_name</span></code> - the name of a pretrained model used to initialize the weights (optional)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code> - the Pytorch device (either <code class="docutils literal notranslate"><span class="pre">cuda</span></code> or <code class="docutils literal notranslate"><span class="pre">cpu</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kwargs</span></code> - the keyword arguments for the provided class</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">NetworkWithPriors</span></code> class has the following keyword arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">embedding_net_type</span></code> - the type of embedding network (e.g. <code class="docutils literal notranslate"><span class="pre">'conv'</span></code> for a 1D CNN, <code class="docutils literal notranslate"><span class="pre">'fno'</span></code> for a FNO)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">embedding_net_kwargs</span></code> - the keyword arguments corresponding to the chosen embedding network (e.g. for the 1D CNN: <code class="docutils literal notranslate"><span class="pre">in_channels</span></code> - the number of input channels of the 1D CNN, <code class="docutils literal notranslate"><span class="pre">hidden_channels</span></code> - list with the number of channels for each layer of the 1D CNN, <code class="docutils literal notranslate"><span class="pre">dim_embedding</span></code> - the dimension of the embedding produced by the 1D CNN, <code class="docutils literal notranslate"><span class="pre">dim_avpool</span></code> - the output size of the adaptive average pooling layer, <code class="docutils literal notranslate"><span class="pre">activation</span></code> - the type of activation function in the 1D CNN)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pretrained_embedding_net</span></code> - the path to the weights of a pretrained embedding network (optional)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dim_out</span></code> - the dimension of the output produced by the MLP (i.e. the number of thin film parameters to be predicted)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dim_conditioning_params</span></code> - the dimension of extra parameters used as input to the network in specific training scenarios (such as the resolution coefficient dq/q), defaults to 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">layer_width</span></code> - the width (i.e. number of neurons) of a linear layer in the MLP</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_blocks</span></code> - the number of residual blocks in the MLP</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repeats_per_block</span></code> - the number of normalization/activation/linear repeats in a block</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_batch_norm</span></code> - whether to use batch normalization in the MLP</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_layer_norm</span></code> - whether to use layer normalization in the MLP (if batch normalization is not used)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mlp_activation</span></code> - the type of activation function in the MLP</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dropout_rate</span></code> - dropout rate for each block</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">conditioning</span></code> - the modality in which the prior bounds are provided to the network, either by concatenating the prior bounds to the data embedding ( <code class="docutils literal notranslate"><span class="pre">'concat'</span></code>) before the MLP or by modulating the intermediated features in each block of the MLP via <a class="reference external" href="https://arxiv.org/abs/1709.07871">FiLM</a> layers (<code class="docutils literal notranslate"><span class="pre">'film'</span></code>) or <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.GLU.html">GLU</a> layers (<code class="docutils literal notranslate"><span class="pre">'glu'</span></code>). If <code class="docutils literal notranslate"><span class="pre">concat_condition_first_layer</span></code> is <code class="docutils literal notranslate"><span class="pre">true</span></code>, the concatenation is performed even when <code class="docutils literal notranslate"><span class="pre">'film'</span></code> or <code class="docutils literal notranslate"><span class="pre">'glu'</span></code> are used.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">network</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">NetworkWithPriors</span>
<span class="w">    </span><span class="nt">pretrained_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;cuda&#39;</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">embedding_net_type</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;conv&#39;</span>
<span class="w">      </span><span class="nt">embedding_net_kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">in_channels</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">        </span><span class="nt">hidden_channels</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">32</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">64</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">128</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">256</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">512</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">        </span><span class="nt">dim_embedding</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">        </span><span class="nt">dim_avpool</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">        </span><span class="nt">use_batch_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">        </span><span class="nt">activation</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;gelu&#39;</span>
<span class="w">      </span><span class="nt">pretrained_embedding_net</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">      </span><span class="nt">dim_out</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">      </span><span class="nt">dim_conditioning_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">      </span><span class="nt">layer_width</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">512</span>
<span class="w">      </span><span class="nt">num_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">      </span><span class="nt">repeats_per_block</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">      </span><span class="nt">residual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">use_batch_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">use_layer_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">      </span><span class="nt">mlp_activation</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;gelu&#39;</span>
<span class="w">      </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0</span><span class="w"> </span>
<span class="w">      </span><span class="nt">conditioning</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;film&#39;</span><span class="w"> </span><span class="c1"># &#39;concat&#39;, &#39;glu&#39;, &#39;film&#39;</span>
<span class="w">      </span><span class="nt">concat_condition_first_layer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">  </span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">training</span></code> key can be used to customize the training settings:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">trainer_cls</span></code> - the class of the trainer (by default <code class="docutils literal notranslate"><span class="pre">PointEstimatorTrainer</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_iterations</span></code> - the total number of training iterations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> - the batch size (number of curves generated at each iteration)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lr</span></code> - the initial learning rate</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">grad_accumulation_steps</span></code> - if larger than 1, training is performed using gradient accumulation with the chosen number of steps</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip_grad_norm_max</span></code> - the maximum norm for gradient clipping (optional)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">update_tqdm_freq</span></code> - the frequency for updating the <a class="reference external" href="https://tqdm.github.io/">tqdm progress bar</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code> - the used <a class="reference external" href="https://pytorch.org/docs/stable/optim">Pytorch optimizer</a>. Default is <code class="docutils literal notranslate"><span class="pre">AdamW</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trainer_kwargs</span></code> - additional trainer keyword arguments. Can be used to specify optional inputs to the network, such as the q values (<code class="docutils literal notranslate"><span class="pre">train_with_q_input</span></code>) or the resolution coefficient (<code class="docutils literal notranslate"><span class="pre">condition_on_q_resolutions</span></code>). Can also be used for setting the optimizer keyword arguments (<code class="docutils literal notranslate"><span class="pre">optim_kwargs</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">callbacks</span></code> - (optional) the callback classes together with their keyword arguments.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logger</span></code> - (optional) a Tensorboard logger for monitoring the progress of the training.</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">training</span><span class="p">:</span>
<span class="w">  </span><span class="nt">trainer_cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">PointEstimatorTrainer</span>
<span class="w">  </span><span class="nt">num_iterations</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100000</span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096</span>
<span class="w">  </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0e-3</span>
<span class="w">  </span><span class="nt">grad_accumulation_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">clip_grad_norm_max</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">  </span><span class="nt">update_tqdm_freq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">AdamW</span>
<span class="w">  </span><span class="nt">trainer_kwargs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">train_with_q_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">condition_on_q_resolutions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">rescale_loss_interval_width</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">use_l1_loss</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">optim_kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">betas</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">0.9</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">0.999</span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0005</span>
<span class="w">  </span><span class="nt">callbacks</span><span class="p">:</span>
<span class="w">    </span><span class="nt">save_best_model</span><span class="p">:</span>
<span class="w">      </span><span class="nt">enable</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">freq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span>
<span class="w">    </span><span class="nt">lr_scheduler</span><span class="p">:</span>
<span class="w">      </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">StepLR</span>
<span class="w">      </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">step_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20000</span>
<span class="w">        </span><span class="nt">gamma</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.5</span>
<span class="w">  </span><span class="nt">logger</span><span class="p">:</span>
<span class="w">    </span><span class="nt">cls</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TensorBoardLogger</span>
<span class="w">    </span><span class="nt">kwargs</span><span class="p">:</span>
<span class="w">      </span><span class="nt">log_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;tensorboard_runs/test_1&quot;</span>
<span class="w">     </span>
</pre></div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "schreiber-lab/reflectorch",
            ref: "dev_vm",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="using_reflectorch_neutron.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Neutron reflectometry use</p>
      </div>
    </a>
    <a class="right-next"
       href="advanced_functionality.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Advanced functionality</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-training-loop">5.1. The training loop</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-the-trainer">5.1.1. Loading the trainer</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-callbacks">5.1.2. Defining callbacks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-training">5.1.3. Run the training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-from-the-terminal">5.1.4. Training from the terminal</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#customizing-the-yaml-configuration-for-training">5.2. Customizing the YAML configuration for training</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Schreiber Lab
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>