general:
  name: l5q256_new_sub_1
  root_dir: null
dset:
  prior_sampler:
    cls: ExpUniformSubPriorSampler
    kwargs:
      params: [
        # thicknesses
        [20., 300., ],
        [20., 300., ],
        [20., 300., ],
        [20., 300., ],
        2.,
        # roughnesses
        [0., 40.],
        [0., 40.],
        [0., 40.],
        [0., 40.],
        2.,
        1.,
        # slds
        [ 2., 17., 1., 5. ],
        [ 2., 17., 1., 5. ],
        [ 2., 17., 1., 5. ],
        [ 2., 17., 1., 5. ],
        19.,
        20.
      ]
      logdist: true
      relative_min_bound_width: 1.0e-2
  q_generator:
    cls: ConstantQ
    kwargs:
      q: [0.02, 0.5, 256]
      remove_zero: false
      fixed_zero: true
  intensity_noise:
    cls: BasicExpIntensityNoise
    kwargs:
      relative_errors: [0.05, 0.2]
      abs_errors: 1.0e-8
      consistent_rel_err: false
      logdist: true
      apply_shift: true
      scale_range: [-0.01, 0.01]
  q_noise:
    cls: BasicQNoiseGenerator
    kwargs:
      shift_std: 5.0e-4
      noise_std: [0., 0.001]
model:
  network:
    cls: SubPriorConvFCEncoder
    pretrained_name: null
    kwargs:
       hidden_dims: [32, 64, 128, 256, 512]
       latent_dim: 12
       conv_latent_dim: 128
       avpool: 4
       use_batch_norm: true
       in_features: 256
       prior_in_features: 24
       hidden_features: 1024
       num_blocks: 2
       pass_bounds: false
       pretrained_conv: null
training:
  num_iterations: 400000
  batch_size: 4096
  lr: 1.0e-5
  update_tqdm_freq: 1
  grad_accumulation_steps: 1
  logger:
    use_neptune: false
  optimizer: AdamW

  callbacks:
    save_best_model:
      enable: true
      freq: 500
    lr_scheduler:
      cls: LogCyclicLR
      kwargs:
        base_lr: 1.0e-5
        max_lr: 1.0e-3
        period: 4000
        gamma: 0.97
        log: false
        start_period: 5
slurm:
  time: 04-00:00:00
  partition: upex
  reservation: false
  chdir: '~/maxwell_output'
