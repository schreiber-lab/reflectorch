general:
  name: val_L2_q109_sim_v2
  root_dir: null
  
dset:

  prior_sampler:
    cls: SubpriorParametricSampler
    kwargs: [de]
      param_ranges:
        thicknesses: [0., 300.]
        roughnesses: [0., 10.]
        slds: [0., 20.]
      bound_width_ranges:
        thicknesses: [ 1.0e-2, 300. ]
        roughnesses: [ 1.0e-2, 10. ]
        slds: [ 1.0e-2, 2. ]
      model_name: standard_model
      max_num_layers: 2
      constrained_roughness: true
      max_thickness_share: 0.5
      logdist: true
      
  q_generator:
    cls: ConstantQ
    kwargs:
      q: [0.02, 0.3, 256]
      remove_zero: false
      fixed_zero: true
      
#   intensity_noise:
#     cls: BasicExpIntensityNoise
#     kwargs:
#       relative_errors: [0.05, 0.2]
#       abs_errors: 1.0e-10
#       consistent_rel_err: false
#       logdist: true
#       apply_shift: true
#       scale_range: [-0.02, 0.02]
  intensity_noise:
    cls: BasicExpIntensityNoise
    kwargs:
      relative_errors: [0.001, 0.002] #[0.01, 0.02]
      abs_errors: 1.0e-10
      consistent_rel_err: false
      logdist: true
      apply_shift: true
      scale_range: [-0.001, 0.001] #[-0.02, 0.02]
      
  q_noise:
    cls: BasicQNoiseGenerator
    kwargs:
      shift_std: 1.0e-7 #5.0e-4
      noise_std: [0., 1.0e-6] #[0., 1.0e-3] #[0., 0.001]
      
  curves_scaler:
    cls: LogAffineCurvesScaler
    kwargs:
      weight: 0.2
      bias: 1.0
      eps: 1.0e-10

model:
  encoder:
    cls: SubPriorConvFCEncoder
    pretrained_name: null
    kwargs:
       hidden_dims: [32, 64, 128, 256, 512]
       latent_dim: 8
       conv_latent_dim: 128
       avpool: 8
       use_batch_norm: true
       in_features: 256
       prior_in_features: 16
       hidden_features: 512
       num_blocks: 3
       pass_bounds: false
       pretrained_conv: null
training:
  num_iterations: 2000
  batch_size: 4096 #4096
  lr: 1.0e-3
  update_tqdm_freq: 1
  grad_accumulation_steps: 1
  logger:
    use_neptune: false
  optimizer: AdamW
#   init_kwargs:
#       optim_kwargs:
#            betas:

  callbacks:
    save_best_model:
      enable: true
      freq: 500
#     lr_scheduler:
#       cls: LogCyclicLR
#       kwargs:
#         base_lr: 1.0e-5
#         max_lr: 5.0e-4
#         period: 5000
#         gamma: 0.95
#         log: false
#         start_period: 10
