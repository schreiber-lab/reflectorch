{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a reflectorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary methods from the `reflectorch` package, as well as othar basic Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "\n",
    "from reflectorch import *\n",
    "from reflectorch.extensions.jupyter import JPlotLoss\n",
    "\n",
    "torch.manual_seed(0); # set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model we use the `Trainer` class, which contains all the components necessary training process such as the data generator, the neural network and the optimizer.\n",
    "\n",
    " We can initialize the trainer according to the specifications defined in a YAML configuration file using the `get_trainer_by_name` method which takes as input the name of the configuration file. If the package was installed in editable model, the configuration files are read from the `configs` directory located inside the repository, otherwise the path to the directory containing the configuration file should also be specified using the `config_dir` argument. The `load_weights` argument should be set to `False` since we want the neural network weights to be randomly initialized for a fresh training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model c_L3_d200_s150_r60_ws5_q03_nq128 loaded. Number of parameters: 4.89 M\n"
     ]
    }
   ],
   "source": [
    "config_name = 'c_L3_d200_s150_r60_ws5_q03_nq128'\n",
    "trainer = get_trainer_by_name(config_name, load_weights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The trainer contains several important attributes we can inspect:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. The Pytorch optimizer. We can observe that the optimizer specified in the configuration is `AdamW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0005\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "The learning rate can be easily changed using `trainer.set_lr(new_lr)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  2. The batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 0.0001, True, False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.batch_size, trainer.lr(), trainer.clip_grad_norm_max, trainer.train_with_q_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. The Pytorch neural network module. We can see that the network is an instance of the class `PriorInformedNetworkConvEmb`. This architecture consists of a multilayer perceptron (MLP) with residual connections, batch normalization layers and GELU activations (`trainer.model.mlp`). A 1D CNN embedding network (`trainer.model.embedding_net`) produces a latent embedding of the input batch of reflectivity curves which is concatenated with the prior bounds for the thin film parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PriorInformedNetworkConvEmb(\n",
       "  (embedding_net): ConvEncoder(\n",
       "    (core): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (avpool): AdaptiveAvgPool1d(output_size=1)\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (mlp): ResidualMLP(\n",
       "    (first_layer): Linear(in_features=150, out_features=512, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x ResidualBlock(\n",
       "        (activation): GELU(approximate='none')\n",
       "        (batch_norm_layers): ModuleList(\n",
       "          (0-1): 2 x BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (linear_layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (last_layer): Linear(in_features=512, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add functionality to the training process using callback objects, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. `JPlotLoss` - allows the interactive visualization of the loss curve when training inside a Jupyter Notebook, the `frequency` argument setting the refresh rate of the interactive widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. `StepLR` - implements a learning rate scheduler which decreases the learning rate in steps (after a number of iterations defined by `step_size` the learning rate is multiplied by the factor `gamma`). Other types of learning rate schedulers can alternatively be used, such as `CyclicLR`, `LogCyclicLR`, `OneCycleLR` or `ReduceLROnPlateau`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. `SaveBestModel` - it enables the periodic saving of the weights of the neural network during training. After a number of iterations defined by the `freq` argument, the weights of the neural network are saved at the specified `path` if the current average loss (computed over the last `average` iterations) is lower than the loss for the previous save. The history of the losses and learning rate values is also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the package is installed in editable mode, the default save path is relative to the repository directory (defined by the global variable `SAVED_MODELS_DIR`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model_name = 'model_' + config_name + '.pt'\n",
    "save_path = str(SAVED_MODELS_DIR / save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the callback objects together in a touple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = (\n",
    "    JPlotLoss(frequency=10, log=True), \n",
    "    StepLR(step_size=1000, gamma=0.9, last_epoch=-1), \n",
    "    SaveBestModel(path=save_path, freq=100, average=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The callbacks can also be initialized directly from the configuration file:\n",
    "`callbacks = get_callbacks_by_name(config_name)`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The training process is initiated by invoking the `train` method of the trainer. This method accepts as arguments the previously defined tuple of callbacks, as well as the number of iterations (batches). Notably, a new batch of data is generated at each iteration, the training taking place in a \"one-epoch regime\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Github Projects\\reflectorch\\reflectorch\\reflectorch\\ml\\basic_trainer.py:138\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, num_batches, callbacks, disable_tqdm, update_tqdm_freq, grad_accumulation_steps)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_tqdm:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_tqdm(pbar, batch_num, update_tqdm_freq)\n\u001b[1;32m--> 138\u001b[0m break_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m break_epoch:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Github Projects\\reflectorch\\reflectorch\\reflectorch\\ml\\basic_trainer.py:268\u001b[0m, in \u001b[0;36m_StackedTrainerCallbacks.end_batch\u001b[1;34m(self, trainer, batch_num)\u001b[0m\n\u001b[0;32m    266\u001b[0m break_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 268\u001b[0m     break_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_num\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m break_epoch\n",
      "File \u001b[1;32mD:\\Github Projects\\reflectorch\\reflectorch\\reflectorch\\extensions\\jupyter\\callbacks.py:35\u001b[0m, in \u001b[0;36mJPlotLoss.end_batch\u001b[1;34m(self, trainer, batch_num)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear:\n\u001b[0;32m     33\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 35\u001b[0m plot_losses(\n\u001b[0;32m     36\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mlosses,\n\u001b[0;32m     37\u001b[0m     log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog,\n\u001b[0;32m     38\u001b[0m     best_epoch\u001b[38;5;241m=\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcallback_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_iteration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mD:\\Github Projects\\reflectorch\\reflectorch\\reflectorch\\extensions\\matplotlib\\losses.py:38\u001b[0m, in \u001b[0;36mplot_losses\u001b[1;34m(losses, log, show, title, x_label, best_epoch, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show:\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_backend_mod()\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2191\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2193\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2194\u001b[0m             filename,\n\u001b[0;32m   2195\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2196\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2197\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2198\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2199\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2200\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[0;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[0;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:3034\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   3032\u001b[0m         artists\u001b[38;5;241m.\u001b[39mremove(spine)\n\u001b[1;32m-> 3034\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_title_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison:\n\u001b[0;32m   3037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:2978\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2976\u001b[0m top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(top, bb\u001b[38;5;241m.\u001b[39mymax)\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mget_text():\n\u001b[1;32m-> 2978\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# update offsetText\u001b[39;00m\n\u001b[0;32m   2979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mget_text():\n\u001b[0;32m   2980\u001b[0m         bb \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axis.py:1336\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[1;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m   1334\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_label_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axis.py:2609\u001b[0m, in \u001b[0;36mYAxis._update_label_position\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;66;03m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[0;32m   2608\u001b[0m \u001b[38;5;66;03m# that have been set by `fig.align_ylabels()`\u001b[39;00m\n\u001b[1;32m-> 2609\u001b[0m bboxes, bboxes2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tick_boxes_siblings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2610\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mget_position()\n\u001b[0;32m   2611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_position \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axis.py:2161\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2159\u001b[0m axis \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_axis_map[name]\n\u001b[0;32m   2160\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 2161\u001b[0m tlb, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2162\u001b[0m bboxes\u001b[38;5;241m.\u001b[39mextend(tlb)\n\u001b[0;32m   2163\u001b[0m bboxes2\u001b[38;5;241m.\u001b[39mextend(tlb2)\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([\u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\text.py:373\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    370\u001b[0m ys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m _, lp_h, lp_d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_text_metrics_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fontproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mismath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTeX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_usetex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m min_dy \u001b[38;5;241m=\u001b[39m (lp_h \u001b[38;5;241m-\u001b[39m lp_d) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines):\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\text.py:69\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache\u001b[1;34m(renderer, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# the passed-in argument do not mess up the cache.\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_text_metrics_with_cache_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\text.py:77\u001b[0m, in \u001b[0;36m_get_text_metrics_with_cache_impl\u001b[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;241m4096\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_text_metrics_with_cache_impl\u001b[39m(\n\u001b[0;32m     75\u001b[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrenderer_ref\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text_width_height_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontprop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mismath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Github Projects\\reflectorch\\reflectorch\\.venv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:221\u001b[0m, in \u001b[0;36mRendererAgg.get_text_width_height_descent\u001b[1;34m(self, s, prop, ismath)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m width, height, descent\n\u001b[0;32m    220\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_font(prop)\n\u001b[1;32m--> 221\u001b[0m \u001b[43mfont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_hinting_flag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m w, h \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_width_height()  \u001b[38;5;66;03m# width and height of unrotated string\u001b[39;00m\n\u001b[0;32m    223\u001b[0m d \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mget_descent()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = 10000\n",
    "trainer.train(num_batches=num_batches, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the history of the losses and learning rates can be accessed via `trainer.losses` and `trainer.lrs`. We can also find them together with the model state_dict in the saved dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'lrs', 'losses', 'prev_save', 'batch_num', 'best_loss'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(save_path).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    ":class: dropdown\n",
    "\n",
    "The saved weights can be loaded into a compatible neural network (`net`) as:\n",
    "\n",
    "```python\n",
    "saved_dict = torch.load(save_path)\n",
    "model_state_dict = saved_dict['model']\n",
    "net.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params', 'scaled_params', 'q_values', 'curves', 'scaled_noisy_curves'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "trainer.loader.calc_denoised_curves = True\n",
    "simulated_data = trainer.loader.get_batch(batch_size=batch_size)\n",
    "\n",
    "simulated_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697ed6b285f14ae7b25e93cd8d4626d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = simulated_data['q_values']\n",
    "scaled_noisy_curves = simulated_data['scaled_noisy_curves']\n",
    "unscaled_noisy_curves = trainer.loader.curves_scaler.restore(scaled_noisy_curves)\n",
    "denoised_curves = simulated_data['curves']\n",
    "scaled_denoised_curves = trainer.loader.curves_scaler.scale(denoised_curves)\n",
    "\n",
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.set_xlabel('q [$^{-1}$]', fontsize=24)\n",
    "    ax.set_ylabel('R$_{scaled}$ (q)', fontsize=24)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "        \n",
    "    ax.scatter(to_np(q[i]), to_np(scaled_noisy_curves[i]), c='blue', s=2.0)\n",
    "    ax.plot(to_np(q[i]), to_np(scaled_denoised_curves[i]), c='green', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 3,  Number of film parameters: 11\n"
     ]
    }
   ],
   "source": [
    "n_layers = simulated_data['params'].max_layer_num\n",
    "n_params = simulated_data['params'].num_params\n",
    "\n",
    "print(f'Number of layers: {n_layers},  Number of film parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 22])\n",
      "torch.Size([64, 278])\n",
      "torch.Size([64, 11])\n",
      "ParametricParams(batch_size=64, max_layer_num=3, device=cuda:0)\n"
     ]
    }
   ],
   "source": [
    "scaled_bounds = simulated_data['scaled_params'][..., n_params:]\n",
    "\n",
    "print(scaled_bounds.shape)\n",
    "\n",
    "scaled_input = torch.cat([scaled_noisy_curves, scaled_bounds], dim=-1).float()\n",
    "\n",
    "print(scaled_input.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    trainer.model.eval()\n",
    "    \n",
    "    scaled_predicted_params = trainer.model(scaled_input)\n",
    "    \n",
    "print(scaled_predicted_params.shape)\n",
    "\n",
    "restored_predictions = trainer.loader.prior_sampler.restore_params(torch.cat([scaled_predicted_params, scaled_bounds], dim=-1))\n",
    "print(restored_predictions)\n",
    "restored_predictions\n",
    "\n",
    "predicted_curves = restored_predictions.reflectivity(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametricParams(batch_size=64, max_layer_num=3, device=cuda:0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.loader.prior_sampler.clamp_params(restored_predictions, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6d64d36a5e487387dd77967c1b8e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=63), Output()), _dom_classes=('widget-interact',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from reflectorch import get_param_labels, get_density_profiles\n",
    "\n",
    "@interact(i=(0, batch_size-1, 1))\n",
    "def plot_refl_curve(i=0):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_ylim(0.5e-10, 5)\n",
    "\n",
    "    ax[0].set_xlabel('q [$^{-1}$]', fontsize=20)\n",
    "    ax[0].set_ylabel('R(q)', fontsize=20)\n",
    "\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[0].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    y_tick_locations = [10**(-2*i) for i in range(6)]\n",
    "    ax[0].yaxis.set_major_locator(plt.FixedLocator(y_tick_locations))\n",
    "        \n",
    "    ax[0].plot(q[i].cpu().numpy(), predicted_curves[i].cpu().numpy() + 1e-10, c='r', lw=1, label='prediction')\n",
    "    ax[0].scatter(q[i].cpu().numpy(), unscaled_noisy_curves[i].cpu().numpy() + 1e-10, c='b', s=2, label='input sim. curve')\n",
    "\n",
    "    ax[0].legend(loc='upper right', fontsize=14)\n",
    "\n",
    "    z_axis = torch.linspace(-200, 1000, 1000, device='cuda')\n",
    "    _, sld_profile_gt, _ = get_density_profiles(\n",
    "         simulated_data['params'].thicknesses, \n",
    "         simulated_data['params'].roughnesses,\n",
    "         simulated_data['params'].slds,\n",
    "         z_axis)\n",
    "    \n",
    "    _, sld_profile_pred, _ = get_density_profiles(\n",
    "         restored_predictions.thicknesses, \n",
    "         restored_predictions.roughnesses,\n",
    "         restored_predictions.slds,\n",
    "         z_axis)\n",
    "    \n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_pred[i].cpu().numpy(), c='r', label='prediction')\n",
    "    ax[1].plot(z_axis.cpu().numpy(), sld_profile_gt[i].cpu().numpy(), c='b', label='ground truth')\n",
    "\n",
    "    ax[1].set_xlabel('z [$$]', fontsize=20)\n",
    "    ax[1].set_ylabel('SLD [$10^{-6} ^{-2}$]', fontsize=20)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax[1].tick_params(axis='both', which='minor', labelsize=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    for l, t, p, min_b, max_b in zip(\n",
    "          get_param_labels(n_layers),\n",
    "          simulated_data['params'].parameters[i], \n",
    "          restored_predictions.parameters[i], \n",
    "          restored_predictions.min_bounds[i], \n",
    "          restored_predictions.max_bounds[i]\n",
    "          ):\n",
    "         print(f'{l.ljust(14)} --> True: {t:.2f} Predicted: {p:.2f}  Input prior bounds: ({min_b:.2f}, {max_b:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing the YAML configuration for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the following we show how the YAML configuration file can be customized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} Sample YAML configuration\n",
    "```yaml\n",
    "\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "  \n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [0., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [-25., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      scale_params_by_ranges: false\n",
    "      scaled_range: [-1., 1.]\n",
    "      \n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      \n",
    "  intensity_noise:\n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      apply_scaling: true\n",
    "      scale_range: [-0.02, 0.02]\n",
    "\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3]\n",
    "      \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "       \n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `general` key, contains the following subkeys:\n",
    "\n",
    "- `name` - name used for saving the model\n",
    "- `root` - path to the root directory, defaults to the package directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "general:\n",
    "  name: c1\n",
    "  root_dir: null\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dset` key defines the settings pertaining to the data generation (i.e. the SLD profile parameterization, the ranges of the thin film parameters, the q values, the noise added to the reflectivity curves and the scaling of the reflectivity curves). It has the following subkeys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `prior_sampler` - responsible for defining the type of SLD parameterization, the ranges on which the thin film parameters are sampled and the ranges on which the widths of the prior bounds are sampled. The `SubpriorParametricSampler` class first samples a center (**C**) from the parameter ranges and a width (**W**) from the bound width ranges. This defines a subinterval delimited by the minimum prior bound **B_min** = **C** - **W**/2 and the maximum prior bound **B_max** = **C** + **W**/2. Then, the values of the parameters (to be used for simulating the reflectivity curves and as ground truth) are uniformly sampled within the interval [**B_min**, **B_max**]. It has the following keyword arguments:\n",
    "- `model_name` - name associated with the type of SLD parameterization. Here, `standard_model` represents the standard box model parameterization of the SLD with the parameters thickness, roughness and real layer SLD.\n",
    "- `max_num_layers` - the number of layers in the thin film (in addition to the substrate)\n",
    "- `param_ranges` - the ranges from which the values of each type of thin film parameter are uniformly sampled (for the standard model `thicknesses`, `roughnesses` and `slds`) \n",
    "- `bound_width_ranges` - the ranges from which the prior bound widths of each type of thin film parameter are uniformly sampled. If the argument `logdist` is set to `true`, the prior bound widths are sampled uniformly on a logarithmic scale instead, biasing the training towards smaller prior bound widths.\n",
    "- `constrained_roughness` - if `true` the sampling of the roughness parameters is constrained such that the roughness of an interface between two layers does not exceed a fraction (defined by the argument `max_thickness_share`) of the thickness of either one of those layers.\n",
    "- `scale_params_by_ranges` - if `true` the parameters are scaled with respect to their ranges, otherwise they are scaled with respect to their subprior bound interval. The default is `false`.\n",
    "- `scaled_range` - the ML-friendly range to which the parameters (and prior bounds) are scaled to, the default is [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} FigureReflectometryNetwork.png\n",
    ":scale: 25\n",
    ":align: center\n",
    ":name: figure_reflectometry_network\n",
    "Parameter sampling process\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  prior_sampler:\n",
    "    cls: SubpriorParametricSampler\n",
    "    kwargs:\n",
    "      param_ranges:\n",
    "        thicknesses: [0., 500.]\n",
    "        roughnesses: [0., 60.]\n",
    "        slds: [-25., 25.]\n",
    "      bound_width_ranges:\n",
    "        thicknesses: [1.0e-2, 500.]\n",
    "        roughnesses: [1.0e-2, 60.]\n",
    "        slds: [ 1.0e-2, 4.]\n",
    "      model_name: standard_model\n",
    "      max_num_layers: 2\n",
    "      constrained_roughness: true\n",
    "      max_thickness_share: 0.5\n",
    "      logdist: false\n",
    "      scale_params_by_ranges: false\n",
    "      scaled_range: [-1., 1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `q_generator` - responsible for generating the transfer vector (q) values at which the reflectivity is to be simulated. We must first specifiy its class. The `ConstantQ` class generates a fixed discretization for all the reflectivity curves in the batch. Its `q` keyword argument is a tuple formatted as *[q_min, q_max, num_q_points]*, which defines the minimum q value, the maximum q value as well as the number of points (including the interval boundaries) to be equidistantlly sampled. Other q generator classes are available such as `VariableQ` (equidistant grid with variable *q_min*, *q_max* and *num_q_points*, further described in the *Advanced functionality* section) and `ConstantAngle` which generates the grid of q values based on equidistantlly sampled scattering angles and the wavelength of the beam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "dset:\n",
    "  q_generator:\n",
    "    cls: ConstantQ\n",
    "    kwargs:\n",
    "      q: [0.02, 0.15, 128]\n",
    "      \n",
    "```      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `q_noise` - responsible for adding noise to the generated q values, which emulates possible measurement errors due to sample misalignment. The `BasicQNoiseGenerator` class can add both systematic q shifts (the same change applied to all q points of a curve) and random noise (different changes applied to each q point of a curve) to the q values of the batch of curves, it has the following arguments:\n",
    "- `shift_std` - the standard deviation of the normal distribution for sampling the systematic q shifts (one value sampled per curve in the batch)\n",
    "- `noise_std` - the standard deviation of the normal distribution for sampling the random q noise (one value sampled per point in the curve). The standard deviation is the same for all curves in the batch if provided as a float, or uniformly sampled from a range for each curve in the batch if provided as a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:\n",
    "  q_noise:\n",
    "    cls: BasicQNoiseGenerator\n",
    "    kwargs:\n",
    "      shift_std: 1.0e-3\n",
    "      noise_std: [0., 1.0e-3]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `intensity_noise` - responsible for adding noise to the reflectivity curves. The `BasicExpIntensityNoise` class has the following arguments:\n",
    "- `relative_errors` - the interval the relative errors are uniformly sampled from\n",
    "- `abs_errors` - absolute error for each curve\n",
    "- `logdist` - if `true` the relative errors are sampled uniformly on a logarithmic scale from the interval defined by `relative_errors`\n",
    "- `apply_shift` - if `true` the entire curve is shifted by a value sampled from the interval defined by the `shift_range` argument\n",
    "- `apply_scaling` - if `true` the entire curve is scaled by a value sampled from the interval defined by the `scale_range` argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:   \n",
    "  intensity_noise:\n",
    "    cls: BasicExpIntensityNoise\n",
    "    kwargs:\n",
    "      relative_errors: [0.0, 0.2]\n",
    "      abs_errors: 0.0\n",
    "      consistent_rel_err: false\n",
    "      logdist: false\n",
    "      apply_shift: true\n",
    "      shift_range: [-0.3, 0.3]\n",
    "      apply_scaling: true\n",
    "      scale_range: [-0.02, 0.02]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. `curves_scaler` - responsible for scaling the reflectivity curves to a ML-friendly range. The `LogAffineCurvesScaler`scales the reflectivity curves (**R**) accoring to the formula: log10(**R** + `eps`) * `weight` + `bias`. The argument `eps` sets the minimum intensity value of the reflectivity curves which is considered. The default values of 1.0e-10 for `eps`, 0.2 for `weight` and 1.0 for `bias` results in the interval [-1, 1] for the scaled reflectivity curves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "dset:    \n",
    "  curves_scaler:\n",
    "    cls: LogAffineCurvesScaler\n",
    "    kwargs:\n",
    "      weight: 0.2\n",
    "      bias: 1.0\n",
    "      eps: 1.0e-10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model` key defines the neural network architecture. Its `encoder` subkey (--*obsolete, to be refractored*--), contains the following subkeys:\n",
    "\n",
    "- `cls` - the class of the neural network\n",
    "- `pretrained_name` - the name of a pretrained model used to initialize the weights (optional)\n",
    "- `kwargs` - the keyword arguments for the provided class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PriorInformedNetworkConvEmb` class has the following keyword arguments:\n",
    "- `in_channels` - the number of input channels of the 1D CNN (1 for reflectivity curves)\n",
    "- `hidden_channels` - list with the number of channels for each layer of the 1D CNN\n",
    "- `dim_embedding` - the dimension of the embedding produced by the 1D CNN\n",
    "- `dim_avpool` - the output size of the adaptive average pooling layer (it scales the input size of the linear layer which produces the embedding as avpool * hidden_dims[-1])\n",
    "- `embedding_net_activation` - the type of activation function in the 1D CNN\n",
    "- `use_batch_norm` - whether to use batch normalization (in both the 1D CNN and the MLP)\n",
    "- `dim_out` - the dimension of the output produced by the MLP (i.e. the number of thin film parameters to be predicted)\n",
    "- `layer_width` - the width (i.e. number of neurons) of a linear layer in the MLP\n",
    "- `num_blocks` - the number of residual blocks in the MLP\n",
    "- `repeats_per_block` - the number of normalization/activation/linear repeats in a block\n",
    "- `mlp_activation` - the type of activation function in the MLP\n",
    "- `dropout_rate` - dropout rate for each block\n",
    "- `pretrained_embedding_net` - the name of a pretrained model used to initialize the weights of the 1D CNN (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```yaml\n",
    "\n",
    "model:\n",
    "  encoder:\n",
    "    cls: PriorInformedNetworkConvEmb\n",
    "    pretrained_name: null\n",
    "    kwargs:\n",
    "      in_channels: 1\n",
    "      hidden_channels: [32, 64, 128, 256, 512]\n",
    "      dim_embedding: 128\n",
    "      dim_avpool: 1\n",
    "      embedding_net_activation: 'gelu'\n",
    "      use_batch_norm: true\n",
    "      dim_out: 8\n",
    "      layer_width: 512\n",
    "      num_blocks: 6\n",
    "      repeats_per_block: 2\n",
    "      mlp_activation: 'gelu'\n",
    "      dropout_rate: 0.0 \n",
    "      pretrained_embedding_net: null\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `training` key can be used to customize the training settings:\n",
    "\n",
    "- `num_iterations` - the total number of training iterations\n",
    "- `batch_size` - the batch size (number of curves generated at each iteration)\n",
    "- `lr` - the initial learning rate\n",
    "- `grad_accumulation_steps` - if larger than 1, training is performed using gradient accumulation with the chosen number of steps\n",
    "- `clip_grad_norm_max` - the maximum norm for gradient clipping (optional)\n",
    "- `train_with_q_input` - must be set to `True` if the q-values are also used as input (i.e. when the FNO embedding network is used)\n",
    "- `update_tqdm_freq` - the frequency for updating the [tqdm progress bar](https://tqdm.github.io/)\n",
    "- `optimizer` - the used [Pytorch optimizer](https://pytorch.org/docs/stable/optim). Default is `AdamW`\n",
    "- `trainer_kwargs` - additional trainer keyword arguments, can be used for setting the optimizer keyword arguments (`optim_kwargs`)\n",
    "- `callbacks` - (optional) the callback classes together with their keyword arguments. Can also be defined directly as illustrated in the previous subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "\n",
    "training:\n",
    "  num_iterations: 10000\n",
    "  batch_size: 4096\n",
    "  lr: 1.0e-4\n",
    "  grad_accumulation_steps: 1\n",
    "  clip_grad_norm_max: null\n",
    "  train_with_q_input: False\n",
    "  update_tqdm_freq: 1\n",
    "  optimizer: AdamW\n",
    "  trainer_kwargs:\n",
    "    optim_kwargs:\n",
    "      betas: [0.9, 0.999]\n",
    "      weight_decay: 0.0005\n",
    "  callbacks:\n",
    "    save_best_model:\n",
    "      enable: true\n",
    "      freq: 500\n",
    "    lr_scheduler:\n",
    "      cls: StepLR\n",
    "      kwargs:\n",
    "        step_size: 500\n",
    "        gamma: 0.5\n",
    "  logger:\n",
    "    use_neptune: false\n",
    "        \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
